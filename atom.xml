<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xeme&#39;s Blog</title>
  
  <subtitle>吴泽鑫的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://thexeme.github.io/"/>
  <updated>2020-07-12T06:04:58.585Z</updated>
  <id>https://thexeme.github.io/</id>
  
  <author>
    <name>TheXeme</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>七月工作笔记1</title>
    <link href="https://thexeme.github.io/2020/07/12/7%E6%9C%88%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B01/"/>
    <id>https://thexeme.github.io/2020/07/12/7%E6%9C%88%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B01/</id>
    <published>2020-07-12T04:00:00.000Z</published>
    <updated>2020-07-12T06:04:58.585Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;七月工作笔记1&quot;&gt;&lt;a href=&quot;#七月工作笔记1&quot; class=&quot;headerlink&quot; title=&quot;七月工作笔记1&quot;&gt;&lt;/a&gt;七月工作笔记1&lt;/h2&gt;&lt;p&gt;2020,07,06~2020,07,10一周工作笔记&lt;/p&gt;
&lt;p&gt;【虎牙-AI工程平台开发组】&lt;/p&gt;
&lt;p&gt;这周主要是接下了AI工程平台里的标注部分的后台，熟悉后台的代码，接一些小的需求&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="虎牙AI工程平台开发组" scheme="https://thexeme.github.io/tags/%E8%99%8E%E7%89%99AI%E5%B7%A5%E7%A8%8B%E5%B9%B3%E5%8F%B0%E5%BC%80%E5%8F%91%E7%BB%84/"/>
    
  </entry>
  
  <entry>
    <title>靶机搭建-dockerFile</title>
    <link href="https://thexeme.github.io/2020/05/24/%E9%9D%B6%E6%9C%BA%E6%90%AD%E5%BB%BA-dockerFile/"/>
    <id>https://thexeme.github.io/2020/05/24/%E9%9D%B6%E6%9C%BA%E6%90%AD%E5%BB%BA-dockerFile/</id>
    <published>2020-05-24T06:57:00.000Z</published>
    <updated>2020-05-24T05:21:49.202Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;靶机搭建：&lt;br&gt;基于docker的靶机环境建立&lt;/p&gt;
&lt;p&gt;使用环境：&lt;br&gt;Docker version 19.03.1&lt;br&gt;windows10&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="网络安全" scheme="https://thexeme.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>靶机渗透-DC3</title>
    <link href="https://thexeme.github.io/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/"/>
    <id>https://thexeme.github.io/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/</id>
    <published>2020-05-23T07:57:00.000Z</published>
    <updated>2020-05-23T08:14:33.573Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;靶机渗透实战：DC3靶机入侵&lt;/p&gt;
&lt;p&gt;使用环境：Linux version 5.2.0-kali2-amd64&lt;br&gt;入侵对象：DC-3靶机-ubuntu 16.04&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="网络安全" scheme="https://thexeme.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>HTTP与FTP服务器搜索</title>
    <link href="https://thexeme.github.io/2020/05/02/HTTP%E4%B8%8EFTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%9C%E7%B4%A2/"/>
    <id>https://thexeme.github.io/2020/05/02/HTTP%E4%B8%8EFTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%9C%E7%B4%A2/</id>
    <published>2020-05-02T01:35:00.000Z</published>
    <updated>2020-05-02T02:02:18.937Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;HTTP与FTP服务器搜索软件，为本人的计算机网络的课程设计作业&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="TCP通信" scheme="https://thexeme.github.io/tags/TCP%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>Docker与DVWA</title>
    <link href="https://thexeme.github.io/2020/03/11/Docker%E4%B8%8EDVWA/"/>
    <id>https://thexeme.github.io/2020/03/11/Docker%E4%B8%8EDVWA/</id>
    <published>2020-03-11T02:51:02.000Z</published>
    <updated>2020-03-11T03:09:21.588Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;由于需要做网络渗透方面的学习，所以需要建立一些靶机，因此使用docker容器，建立DVWA&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="网络安全" scheme="https://thexeme.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>支持向量机</title>
    <link href="https://thexeme.github.io/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <id>https://thexeme.github.io/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</id>
    <published>2020-02-25T05:00:00.000Z</published>
    <updated>2020-02-25T05:14:22.833Z</updated>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;由于内容比较多，所以写了比较长的时间，从22号断断续续写到25号才写完&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;间隔与支持向量&quot;&gt;&lt;a href=&quot;#间隔与支持向量&quot; class=&quot;headerlink&quot; title=&quot;间隔与支持向量&quot;&gt;&lt;/a&gt;间隔与支持向量&lt;/h2&gt;&lt;p&gt;给定训练样本集：&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/训练样本集.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;分类学习最基本的想法就是基于训练、集D 在样本空间中找到一个划分超平面、将&lt;br&gt;不同类别的样本分开。&lt;/p&gt;
&lt;p&gt;在样本空间中，划分超平面可通过如下线性方程来描述:&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/线性方程.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;其中w = (ω1,ω2, … ,ωd) 为法向量，决定了超平面的方向; b 为位移项，决定了超平面与原点之间的距离.显然，划分超平面可被法向量ω和位移b确定，下面我们将其记为(ω,b).样本空间中任意点x到超平面(ω,b)的距离可写为:&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/点到平面距离.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;证明如下：&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/点到平面距离证明.jpg&quot; style=&quot;zoom:50%;&quot;&gt;

&lt;p&gt;假设超平面(ω,b)能将训练样本正确分类，即对于(xi,yi) ∈ D , 若yi = +1 , 则有 ωTxi+b&amp;gt;0;若yi = -1 , 则有 ωTxi+b&amp;lt;0。令：(ω和b参数的约束式)&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量机基本分类式.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;如下图所示，距离超平面最近的这几个训练样本点使上式的等号成立，它们被称为”支持向量” (support vector) ，两个异类支持向量到超平面的距离之和为:&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/异类间隔.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;它被称为间隔。(使用上面的点到超平面距离公式代入上面正确分类的定义式即可很容易推导出)&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量与间隔.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;欲找到具有”最大间隔” (maximum margin) 的划分超平面，也就是要找&lt;br&gt;到能满足式中约束的参数ω和b ， 使得γ最大，即:&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/约束式写法1.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;其中s.t. ，指 subject to，受限制于… ，即指代2式为约束，然后使得1式最大。之所以可以写成2式，是因为在负样本中，亦有： (-1)*(-1)=1&amp;gt;0 &lt;/p&gt;
&lt;p&gt;注：在此处，间隔看似仅与ω有关，但事实上b通过约束式暗中地影响着ω的取值，进而对间隔产生影响&lt;/p&gt;
&lt;p&gt;重新看回上式为了最大化1式(最大化间隔)，只需使其分母最小，因此可以等价为：（6.6）&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/约束式写法2.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;这就是支持向量机(Support Vector Machine，简称SVM) 的基本型.&lt;/p&gt;
&lt;p&gt;最后，超平面对应的模型为：&lt;/p&gt;
&lt;img src=&quot;/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/超平面模型.png&quot; style=&quot;zoom:100%;&quot;&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="https://thexeme.github.io/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://thexeme.github.io/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2020-02-20T14:36:30.000Z</published>
    <updated>2020-02-21T04:53:12.706Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;神经元模型&quot;&gt;&lt;a href=&quot;#神经元模型&quot; class=&quot;headerlink&quot; title=&quot;神经元模型&quot;&gt;&lt;/a&gt;神经元模型&lt;/h2&gt;&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/神经元模型.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;上图为”M-P 神经元模型” [McCulloch and Pitts, 1943] 。&lt;/p&gt;
&lt;p&gt;神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阀值进行比较，然后通过”激活函数” (activation function) 处理以产生神经元的输出.&lt;/p&gt;
&lt;p&gt;理想中的激活函数是阶跃函数，但阶跃函数具有不连续、不光滑等不太好的性质，因此实际常用Sigmoid函数作为激活函数（有时也称为”挤压函数” (squashing function）)，对数几率函数时Sigmoid函数的代表。(见前面线性模型中谈到的对数几率回归)&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/激活函数.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络.&lt;/p&gt;
&lt;h2 id=&quot;感知机与多层网络&quot;&gt;&lt;a href=&quot;#感知机与多层网络&quot; class=&quot;headerlink&quot; title=&quot;感知机与多层网络&quot;&gt;&lt;/a&gt;感知机与多层网络&lt;/h2&gt;&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/感知机网络结构.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;y = f(Σωixi - θ) ;一般地，给定训练数据集权重ωi(i=1,2,…,n) 以及阔值θ。可通过学习得到.这样，权重和阈值的学习就可统一为权重的学习.感知机学习规则非常简单，对训练样例（x,y) ，若当前感知机的输出为y拔， 则感知机权重将这样调整:&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/感知机权重调整.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;其中 0&amp;lt;n&amp;lt;1 ，称为学习率(learning rate)。可看出，若感知机对训练样例(x,y) 预测正确，即y拔 = y ， 则感知机不发生变化，否则将根据错误的程度进行权重调整.&lt;/p&gt;
&lt;p&gt;若两类模式是线性可分的，即存在一个线性超平面能将它们分开。”非线性可分”意味着用线性起平面无法划分。与或非问题时线性可分的，而异或是非线性可分的。在非线性可分问题中，单层感知机学习过程将会发生震荡(fluctuation) ,ω难以稳定下来，不能求得合适解，例如单层感知机不能解决异或这样简单的非线性可分问题.&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/与或非异或.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;要解决非线性可分问题，需考虑多层功能神经元. 例如下图中这个简单的两层感知机就能解决异或问题.  输出层与输入层之间的一层神经元，被称为隐层或隐含层(hidden layer) ，隐含层和输出层神经元都是拥有激活函数的功能神经元.&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/两层感知机.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;更一般的，常见的神经网络是形如下图所示的层级结构，每层神经元与下层神经元全互连，神经元之间不存在同层连接， 也不存在跨层连接. 这样的神经网络结构通常称为” 多层前馈神经网络” (multi-layer feedforward neural networks) ，（”前债”并不意味着网络中信号不能向后传，而是指网络拓扑结构上不存在环或回路）其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工。输入层神经元仅是接受输入，不进行函数处理。&lt;/p&gt;
&lt;p&gt;神经网络的学习过程，就是根据训练数据来调整神经元之间的”连接权” (connection weight) 以及每个功能神经元的阈值;换言之，神经网络”学”到的东西，蕴涵在连接权与阈值中。&lt;/p&gt;
&lt;h2 id=&quot;误差逆传播算法&quot;&gt;&lt;a href=&quot;#误差逆传播算法&quot; class=&quot;headerlink&quot; title=&quot;误差逆传播算法&quot;&gt;&lt;/a&gt;误差逆传播算法&lt;/h2&gt;&lt;p&gt;欲训练多层网络，需要更强大的学习算法，如误差逆传播(errorBackPropagation，简称BP)算法。BP 算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络例如训练递归神经网络[1987].&lt;/p&gt;
&lt;p&gt;假定：拥有d 个输入神经元、l 个输出神经元、q 个隐层神经元的多层前馈网络结构，其中输出层第j个神经元的阀值用θj 表示，隐层第h个神经元的阔值用γh 表示.输入层第i个神经元与隐层第h个神经元之间的连接权为νih，隐层第h个神经元与输出层第j个神经元之间的连接权为ωhj. 记隐层第h个神经元接收到的输入为: &lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/隐含层接收.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;输出层第j个神经元接收到的输入为:(其中bh 为隐层第h个神经元的输出)&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/输出层接收.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP网络.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;网络中有(d+ l +1) q + l 个参数需确定:输入层到隐层的dxq个权值、隐层到输出层的q x l 个权值、q 个隐层神经元的阔值、l个输出层神经元的阔值. BP 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计&lt;/p&gt;
&lt;p&gt;BP 算法基于梯度下降(gradient descent)策略， 以目标的负梯度方向对参数进行调整.&lt;/p&gt;
&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP1.jpg&quot; style=&quot;zoom:50%;&quot;&gt;

&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP2.jpg&quot; style=&quot;zoom:50%;&quot;&gt;

&lt;img src=&quot;/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP3.jpg&quot; style=&quot;zoom:50%;&quot;&gt;

&lt;p&gt;学习率 0&amp;lt;η&amp;lt;1 控制着每一轮迭代中的更新步长,太大则容易振荡，太小则收敛速度又会过慢，常设置为η=0.1 。 有时为了做精细调节，可使每层神经元使用不同的学习率。&lt;/p&gt;
&lt;p&gt;BP算法的工作流程：对每个训练样例，BP 算法执行以下操作:&lt;br&gt;先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果;然后计算输出层的误差(第4-5行) ，再将误差逆向传播至隐层神经元(第6 行) ，最后根据隐层神经元的误差来别连接权和阈值进行调整(第7行).该法代过程循环进行，直到达到某些停止条件为止，比如误差已经很小，或迭代次数达到上限。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>决策树1</title>
    <link href="https://thexeme.github.io/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/"/>
    <id>https://thexeme.github.io/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/</id>
    <published>2020-02-17T08:36:30.000Z</published>
    <updated>2020-02-19T04:27:46.568Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本流程&quot;&gt;&lt;a href=&quot;#基本流程&quot; class=&quot;headerlink&quot; title=&quot;基本流程&quot;&gt;&lt;/a&gt;基本流程&lt;/h2&gt;&lt;p&gt;一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点;叶结点对应于决策结果(底部决策完毕)，其他每个结点则对应于一个属性测试;每个结点包含的样本集合根据属性测试的结果被划分到子结点中(子决策);根结点包含样本全集.从根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的”分而治之” (divide-and-conquer) 策略。&lt;/p&gt;
&lt;p&gt;决策树的生成是一个递归过程.在决策树基本算法中，有三种情形会导致递归返回:&lt;br&gt;(1) 当前结点包含的样本全属于同一类别，无需划分(已经可以得出是正样本还是负样本);&lt;br&gt;(2) 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分;&lt;br&gt;(3) 当前结点包含的样本集合为空，不能划分.&lt;/p&gt;
&lt;p&gt;在第(2)种情形下，我们把当前结点标记为叶结点，井将其类别设定为该结点所含样本最多的类别;&lt;br&gt;在第(3) 种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别.&lt;br&gt;注意这两种情形的处理实质不同:情形(2)是在利用当前结点的后验分布，而情形(3)则是把父结点的样本分布作为当前结点的先验分布.&lt;/p&gt;
&lt;h2 id=&quot;划分选择&quot;&gt;&lt;a href=&quot;#划分选择&quot; class=&quot;headerlink&quot; title=&quot;划分选择&quot;&gt;&lt;/a&gt;划分选择&lt;/h2&gt;&lt;p&gt;决策树学习的关键是如何选择最优划分属性。&lt;/p&gt;
&lt;h3 id=&quot;信息增益&quot;&gt;&lt;a href=&quot;#信息增益&quot; class=&quot;headerlink&quot; title=&quot;信息增益&quot;&gt;&lt;/a&gt;信息增益&lt;/h3&gt;&lt;p&gt;“信息熵” (information entropy)是度量样本集合纯度最常用的一种指标.假定当前样本集合D 中第k类样本所占的比例为Pk (k = 1, 2,. . . , IYI) ，则D的信息熵定义为:(值越小，则D的纯度越高)(在好瓜坏瓜分类中，可以理解为好瓜比例远高于坏瓜比例，或者反过来，因为通过求导可以知道，就是要使得样本比例中某一部分远高于其他；依此，用信息熵最小，就可以知道挑出某样本的“可行率”,若信息熵值越高，则越混乱(平均)，纯度越低)&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息熵.png&quot; style=&quot;zoom:100%;&quot;&gt;



&lt;p&gt;假定离散属性a有V个可能的取值，给分支结点赋予权重IDVI / IDI ，即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集D进行划分所获得的”信息增益” (information gain)&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息增益.png&quot; style=&quot;zoom:75%;&quot;&gt;

&lt;p&gt;一般而言，信息增益越大(子类的信息熵更小，因此说明这个分类器更能挑)，则意味着使周属性a来进行划分所获得的”纯度提升”越大.因此，我们可用信息增益来进行决策树的划分属性选择。ID3 决策树学习算法(Iterative Dichotomiser 迭代二分器)就是以信息增益为准则来选择划分属性。&lt;/p&gt;
&lt;p&gt;通过在每个叶子节点计算使用剩余的所有可用属性会在此处的信息增益，挑出最高的作为此叶子节点的判别属性，就可以获得决策树(ID3决策树)&lt;/p&gt;
&lt;h3 id=&quot;增益率&quot;&gt;&lt;a href=&quot;#增益率&quot; class=&quot;headerlink&quot; title=&quot;增益率&quot;&gt;&lt;/a&gt;增益率&lt;/h3&gt;&lt;p&gt;但是信息增益准则也有坏处，信息增益准则对可取值数目较多的属性有所偏好。比如，将所有的样本单独分为一分支，这样每个节点仅有一个样本，分支节点纯度已达最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测.&lt;/p&gt;
&lt;p&gt;为减少这种偏好可能带来的不利影响，著名的 C4.5 决策树算法不直接使用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性.采用与式(4.2) 相同的符号表示，增益率定义为：&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/增益率.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;其中:属性a的”固有值”:属性a的可能取值数目越多(即V越大)，则IV(a) 的值通常会越大.&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/固有值.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;由于增益率准则对可取值数目较少的属性有所偏好，因此 C4.5决策树算法不直接使用增益率，而是 : 先从候选划分属性中找出信息增益高于平均水平的属性，再从&lt;br&gt;中选择增益率最高的.&lt;/p&gt;
&lt;h3 id=&quot;基尼指数&quot;&gt;&lt;a href=&quot;#基尼指数&quot; class=&quot;headerlink&quot; title=&quot;基尼指数&quot;&gt;&lt;/a&gt;基尼指数&lt;/h3&gt;&lt;p&gt;CART 决策树使用”基尼指数” (Gini index)来选择划分属性.数据集D的纯度可用基尼值来度量:&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼值.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;直观来说， Gini(D) 反映了从数据集D中随机抽取两个样本其类别标记不一致的概率.因此，Gini(D) 越小，则数据集D 的纯度越高.&lt;/p&gt;
&lt;p&gt;属性α 的基尼指数定义为：&lt;/p&gt;
&lt;img src=&quot;/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼指数.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;于是，CART 决策树在候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>相机运动方向检测2</title>
    <link href="https://thexeme.github.io/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/"/>
    <id>https://thexeme.github.io/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/</id>
    <published>2020-02-13T03:07:07.000Z</published>
    <updated>2020-02-19T05:03:18.812Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;最终效果&quot;&gt;&lt;a href=&quot;#最终效果&quot; class=&quot;headerlink&quot; title=&quot;最终效果&quot;&gt;&lt;/a&gt;最终效果&lt;/h2&gt;&lt;p&gt;关于之前开的相机运动方向检测的代码实现，目前已经大致完成&lt;/p&gt;
&lt;img src=&quot;/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result_mainPage.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;测试视频，效果如下：&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器视觉" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>线性模型2</title>
    <link href="https://thexeme.github.io/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/"/>
    <id>https://thexeme.github.io/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/</id>
    <published>2020-02-12T02:06:30.000Z</published>
    <updated>2020-02-12T04:37:20.677Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;类别&quot;&gt;&lt;a href=&quot;#类别&quot; class=&quot;headerlink&quot; title=&quot;类别&quot;&gt;&lt;/a&gt;类别&lt;/h2&gt;&lt;h3 id=&quot;线性模型中的多分类学习&quot;&gt;&lt;a href=&quot;#线性模型中的多分类学习&quot; class=&quot;headerlink&quot; title=&quot;线性模型中的多分类学习&quot;&gt;&lt;/a&gt;线性模型中的多分类学习&lt;/h3&gt;&lt;p&gt;现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。&lt;/p&gt;
&lt;p&gt; 多分类学习的基本思路是”拆解法”，即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成.最经典的拆分策略有三种. “一对一” (One vs. One，简称OvO) 、”一对其余” (One vs. Rest ，简称OvR)和”多对多” (Many vs. Many，简称MvM)。&lt;/p&gt;
&lt;h4 id=&quot;OvO与OvR&quot;&gt;&lt;a href=&quot;#OvO与OvR&quot; class=&quot;headerlink&quot; title=&quot;OvO与OvR&quot;&gt;&lt;/a&gt;OvO与OvR&lt;/h4&gt;&lt;p&gt;OvO 将N 个类别两两配对，从而产生N(N 一1)/2 个二分类任务，最终结果可通过投票产生。OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器.在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果。若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。下图为OvO与OvR的示意图：&lt;/p&gt;
&lt;img src=&quot;/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/OvO与OvR.png&quot; style=&quot;zoom:80%;&quot;&gt;



&lt;p&gt;OvR只需训练N个分类器， 而OvO需训练N(N - 1)/2 个分类器， 因此， OvO的存储开销和测试间开销通常比OvR 更大. 但在训练时，OvR的每个分类器均使用全部训练样例，而OvO的每个分类器仅用到两个类的样例，因此，在类别很多时，OvO的训练时间开销通常比OvR更小. 预测性能在多数情形下两者差不多.&lt;/p&gt;
&lt;h4 id=&quot;MvM&quot;&gt;&lt;a href=&quot;#MvM&quot; class=&quot;headerlink&quot; title=&quot;MvM&quot;&gt;&lt;/a&gt;MvM&lt;/h4&gt;&lt;p&gt;MvM 是每次将若干个类作为正类，若干个其他类作为反类. MvM的正、反类构造必须有特殊的设计，不能随意选取.最常用的MvM技术是”纠错输出码” (Error CorrectingOutput Codes，简称ECOC).它尽可能在解码过程中具有容错性. &lt;/p&gt;
&lt;h5 id=&quot;Error-CorrectingOutput-Codes-ECOC&quot;&gt;&lt;a href=&quot;#Error-CorrectingOutput-Codes-ECOC&quot; class=&quot;headerlink&quot; title=&quot;Error CorrectingOutput Codes(ECOC)&quot;&gt;&lt;/a&gt;Error CorrectingOutput Codes(ECOC)&lt;/h5&gt;&lt;p&gt;ECOC 工作过程主要分为两步:&lt;br&gt;编码:对N个类别做M次划分， 每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集;这样一共产生M个训练集，可训练出M个分类器.&lt;br&gt;解码:M个分类器分别对测试样本进行预测，这些预测标记组成一个编码.将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果.&lt;/p&gt;
&lt;img src=&quot;/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/ECOC.png&quot; style=&quot;zoom:80%;&quot;&gt;

&lt;p&gt;ECOC 编码示意图”+1” 、”-1” 分别表示学习器f将该类样本作为正、反例;三元码中”0” 表示f不使用该类样本&lt;br&gt;一般来说，对同一个学习任务， ECOC 编码越长，纠错能力越强.然而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大;另外，对有限类别数，可能的组合数目是有限的。&lt;/p&gt;
&lt;p&gt;对OvR 、MvM 来说，由于对每个类进行了相同的处理，其拆解出的二分类任务中类别不平衡的影响会相互抵消，因此通常不需专门处理.&lt;/p&gt;
&lt;h3 id=&quot;类别不平衡问题-class-imbalance&quot;&gt;&lt;a href=&quot;#类别不平衡问题-class-imbalance&quot; class=&quot;headerlink&quot; title=&quot;类别不平衡问题(class-imbalance)&quot;&gt;&lt;/a&gt;类别不平衡问题(class-imbalance)&lt;/h3&gt;&lt;p&gt;如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰.例如有998个反例，但正例只有2个，那么学习方法只需返回一个永远将新样本预测为反例的学习器，就能达到99.8%的精度;然而这样的学习器往往没有价值，因为它不能预测出任何正例.&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>线性模型1</title>
    <link href="https://thexeme.github.io/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/"/>
    <id>https://thexeme.github.io/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/</id>
    <published>2020-02-10T08:55:02.000Z</published>
    <updated>2020-02-20T04:11:08.008Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;线性模型的基本形式&quot;&gt;&lt;a href=&quot;#线性模型的基本形式&quot; class=&quot;headerlink&quot; title=&quot;线性模型的基本形式&quot;&gt;&lt;/a&gt;线性模型的基本形式&lt;/h2&gt;&lt;img src=&quot;/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/基本形式.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;h3 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归&quot; class=&quot;headerlink&quot; title=&quot;线性回归&quot;&gt;&lt;/a&gt;线性回归&lt;/h3&gt;&lt;p&gt;“线性回归” (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。通常使用均方误差，亦称平方损失，来作为性能度量，试图使均方误差最小。&lt;/p&gt;
&lt;p&gt;基于均方误差最小化来进行模型求解的方法称为”最小二乘法” (least suare method). 在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.(最小二乘法用途很广，不仅限于线性回归)&lt;/p&gt;
&lt;p&gt;在求解使得均方差最小化的过程中，称为线性回归模型对最小二乘的参数估计。我们可对其均方差求导，另求导式为零，则可得w与b的最优解。&lt;/p&gt;
&lt;p&gt;然而现实中，往往会求出多个解。这时选择哪一个作为解进行输出，则由算法的归纳偏好决定。常见的做法是引入正则化(regularization) 项.如，假设我们认为示例所对应的输出标记是在指数尺度上变化，则可以使得 lny = wx +b 。这就是”对数线性回归” (log-linear regression)。&lt;/p&gt;
&lt;p&gt;更一般地，考虑单调可微函数g(.) ， 令 g(y) = wx + b , 这样得到的模型称为” 广义线性模型” (generalized linear model) ，其中函数g() 称为”联系函数” (link function)。&lt;/p&gt;
&lt;h3 id=&quot;对数几率回归&quot;&gt;&lt;a href=&quot;#对数几率回归&quot; class=&quot;headerlink&quot; title=&quot;对数几率回归&quot;&gt;&lt;/a&gt;对数几率回归&lt;/h3&gt;&lt;p&gt;若要做的是分类任务，只需找一个单调可做函数将分类任务的真实标记y与线性回归模型的预测值联系起来。&lt;/p&gt;
&lt;img src=&quot;/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/单位阶跃函数与对数几率函数.png&quot; style=&quot;zoom:100%;&quot;&gt;

&lt;p&gt;上图中，左式是对数几率函数；右式是单位阶跃函数&lt;/p&gt;
&lt;p&gt;从图3.2 可看出，单位阶跃函数不连续，因此不能直接使用，于是我们使用另外的单调可微的连续函数：对数几率函数。&lt;/p&gt;
&lt;p&gt;对数几率函数是一种”Sigmoid 函数” (Sigmoid 函数即形似s的函数)，它将z值转化为一个接近0或1 的y值并且其输出值在z=0 附近变化很陡.将对数几率函数作为g()使用于广义线性模型 g(y) = wx + b 中即可将分类标记与回归模型联系起来。&lt;/p&gt;
&lt;p&gt;这个方法是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为”对数几率回归”，虽然它的名字是”回归”，但实际是一种分类学习方法。&lt;/p&gt;
&lt;p&gt;在其求解中，我们可通过”极大似然法” (maximum likelihood method)来估计ω和b。即令每个样本属于其真实标记的概率越大越好。最终得出的式子是关于β 的高阶可导连续凸函数，根据凸优化理论，经典的数值优化算法如梯度下降法(gradient descent method) 、牛顿法(Newton method)等都可求得其最优解。&lt;/p&gt;
&lt;h4 id=&quot;梯度下降&quot;&gt;&lt;a href=&quot;#梯度下降&quot; class=&quot;headerlink&quot; title=&quot;梯度下降&quot;&gt;&lt;/a&gt;梯度下降&lt;/h4&gt;&lt;p&gt;有一可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快。因为梯度的方向就是函数之变化最快的方向。所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是测量下降方向的手段。&lt;/p&gt;
&lt;p&gt;在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率；在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器学习" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>相机运动方向检测1</title>
    <link href="https://thexeme.github.io/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/"/>
    <id>https://thexeme.github.io/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/</id>
    <published>2020-02-08T11:03:07.000Z</published>
    <updated>2020-02-11T11:07:18.195Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h2&gt;&lt;p&gt;代码实现相机运动方向的检测，用于后面的相机运动补偿。&lt;br&gt;目前还未完成，本篇仅为今日的小结&lt;/p&gt;
&lt;h2 id=&quot;算法大致思路&quot;&gt;&lt;a href=&quot;#算法大致思路&quot; class=&quot;headerlink&quot; title=&quot;算法大致思路&quot;&gt;&lt;/a&gt;算法大致思路&lt;/h2&gt;&lt;p&gt;该算法思路仅为当前思路，后续还会继续改进&lt;/p&gt;
&lt;p&gt;对于每一帧：&lt;br&gt;1、提取其Surf特征点&lt;br&gt;2、与上一帧的特征点进行匹配，这里可以使用FlannBased与BruteForceMatcher，FlannBased更快而BruteForceMatcher更精确；考虑到视频处理的实时性，本人目前使用FlannBased&lt;br&gt;3、基于距离筛除一些不太可能的匹配，此步骤的前提是场景不会发生形变&lt;br&gt;4、根据已经匹配的特征点及其移动距离与方向，从而获取当前相机在此参考系下的移动情况&lt;/p&gt;
&lt;h3 id=&quot;主要使用到数据结构与对象&quot;&gt;&lt;a href=&quot;#主要使用到数据结构与对象&quot; class=&quot;headerlink&quot; title=&quot;主要使用到数据结构与对象&quot;&gt;&lt;/a&gt;主要使用到数据结构与对象&lt;/h3&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cv::Ptr&amp;lt;SurfFeatureDetector&amp;gt; detector;&lt;span class=&quot;comment&quot;&gt;//检测器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;cv::KeyPoint&amp;gt; key_points_1, key_points_2;&lt;span class=&quot;comment&quot;&gt;//提取的特征点序列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cv::Mat descriptors1, descriptors2;&lt;span class=&quot;comment&quot;&gt;//特征描述子&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cv::Ptr&amp;lt;cv::DescriptorMatcher&amp;gt; matcher = &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    cv::DescriptorMatcher::create(&lt;span class=&quot;string&quot;&gt;&quot;FlannBased&quot;&lt;/span&gt;);&lt;span class=&quot;comment&quot;&gt;//FlannBased匹配&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;cv::DMatch&amp;gt; dmatches;&lt;span class=&quot;comment&quot;&gt;//匹配序列&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h3 id=&quot;目前进度&quot;&gt;&lt;a href=&quot;#目前进度&quot; class=&quot;headerlink&quot; title=&quot;目前进度&quot;&gt;&lt;/a&gt;目前进度&lt;/h3&gt;&lt;img src=&quot;/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/match1.png&quot; style=&quot;zoom:125%;&quot;&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器视觉" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>运动相机下的运动目标跟踪3</title>
    <link href="https://thexeme.github.io/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/"/>
    <id>https://thexeme.github.io/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/</id>
    <published>2020-02-07T07:46:21.000Z</published>
    <updated>2020-02-07T07:06:45.316Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;继上篇，以下为2月7日研究《Moving Objects Detection with a Moving Camera: A Comprehensive Review》的运动分割法部分的笔记&lt;/p&gt;
&lt;h3 id=&quot;Motion-segmentation-运动分割法2&quot;&gt;&lt;a href=&quot;#Motion-segmentation-运动分割法2&quot; class=&quot;headerlink&quot; title=&quot;Motion segmentation 运动分割法2&quot;&gt;&lt;/a&gt;Motion segmentation 运动分割法2&lt;/h3&gt;&lt;p&gt;《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(2015)提出了一个基于轨迹的分水岭分割算法。在应用一个双边的滤波器去柔化图像并增强edges后，无关梯度会被最小化，并且将轨迹点选为标签。这些标签将会用于watershed algorithm (分水岭算法,根据分水岭的构成来考虑图像的分割) 的seeds从而获得分割结果。在这个结果中，会根据轨迹的标签，将分割结果的相应标为前景与背景。最后，利用马尔可夫随机场算法(Markov Random Field，MRF)，让其中的能量函数最小化，使得用前景背景信息推断没有标签的部分的标签。&lt;/p&gt;
&lt;img src=&quot;/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P1_2015.png&quot; style=&quot;zoom:75%;&quot;&gt;

&lt;p&gt;上图中，红色点代表为检测出的背景部分，蓝色点代表检测出的前景部分；其中有一些由于噪点而误检测的特征点可以使用PCA算法筛除&lt;/p&gt;
&lt;p&gt;《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了Multi-Layer Background Subtraction(多层的背景差法)。他们使用了多标签的分割，而非二值标签的分割。每一个动作集群点都会被联系到一层中。在每一层中，像素的动作都会由Gaussian Belief Propagation (GaBP)(高斯置信度传播算法)评估。之后，由外观模型、先前的概率图、motion estimation(动作评估)去计算之后的概率图。多标签的分割是正是基于由MRF算法中最小化能量函数得出的概率图计算的。&lt;/p&gt;
&lt;img src=&quot;/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P2_2017.png&quot; style=&quot;zoom:75%;&quot;&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器视觉" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>运动相机下的运动目标跟踪2</title>
    <link href="https://thexeme.github.io/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/"/>
    <id>https://thexeme.github.io/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/</id>
    <published>2020-02-05T08:40:02.000Z</published>
    <updated>2020-02-05T14:16:42.276Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;以下为阅读《Moving Objects Detection with a Moving Camera: A Comprehensive Review》随读笔记&lt;/p&gt;
&lt;h3 id=&quot;Motion-segmentation-运动分割法&quot;&gt;&lt;a href=&quot;#Motion-segmentation-运动分割法&quot; class=&quot;headerlink&quot; title=&quot;Motion segmentation 运动分割法&quot;&gt;&lt;/a&gt;Motion segmentation 运动分割法&lt;/h3&gt;&lt;p&gt;运动分割法的大体思路为利用特征点的轨迹来分割每一帧，分成静态背景与移动物体。&lt;/p&gt;
&lt;img src=&quot;/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/运动分割法example.png&quot; style=&quot;zoom:125%;&quot;&gt;

&lt;p&gt;《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(oct 2015)提出：根据特征点的轨迹相似度，并利用PCA算法(主成分分析算法)筛除false trajectories，从而获取几类集群特征点。&lt;/p&gt;
&lt;p&gt;《a probabilistic model for causal motion segmentation in moving camera videos》(2016)使用了稠密光流差、旋转流差，从而获得了物体的移动流。然后由平移流(translational flow)估计角度场，并根据每个平移流的平移大小作为该平移角度的可靠性指标，然后由符合条件的流动角度的可能性评估每个像素的流动方向。最后，用贝叶斯公式(Bayes’ rule)获得每个像素的次可能移动，然后会被用于最后的分割当中。作者还提出了，利用一个修正的RANSAC算法选择3个超像素，然后用于去分割视频的第一帧，从而用于后续的估计背景的移动以抵消相机的晃动。&lt;/p&gt;
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器视觉" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>运动相机下的运动目标跟踪1</title>
    <link href="https://thexeme.github.io/2020/02/03/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA1/"/>
    <id>https://thexeme.github.io/2020/02/03/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA1/</id>
    <published>2020-02-03T12:39:02.000Z</published>
    <updated>2020-02-05T02:56:17.963Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;h1 id=&quot;Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera&quot;&gt;&lt;a href=&quot;#Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera&quot;
        
      
    
    </summary>
    
    
      <category term="技术" scheme="https://thexeme.github.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="机器视觉" scheme="https://thexeme.github.io/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>My First Blog in here</title>
    <link href="https://thexeme.github.io/2020/01/01/FirstBlog/"/>
    <id>https://thexeme.github.io/2020/01/01/FirstBlog/</id>
    <published>2019-12-31T16:00:00.000Z</published>
    <updated>2020-02-19T05:09:58.005Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;欢迎来到吴泽鑫的博客！&lt;/p&gt;
&lt;h2 id=&quot;About-me&quot;&gt;&lt;a href=&quot;#About-me&quot; class=&quot;headerlink&quot; title=&quot;About me&quot;&gt;&lt;/a&gt;About me&lt;/h2&gt;&lt;h3 id=&quot;代码仓库&quot;&gt;&lt;a href=&quot;#代码仓库&quot;
        
      
    
    </summary>
    
    
      <category term="生活" scheme="https://thexeme.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://thexeme.github.io/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
</feed>
