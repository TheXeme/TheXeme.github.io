<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>决策树1</title>
    <url>/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/</url>
    <content><![CDATA[<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点;叶结点对应于决策结果(底部决策完毕)，其他每个结点则对应于一个属性测试;每个结点包含的样本集合根据属性测试的结果被划分到子结点中(子决策);根结点包含样本全集.从根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的”分而治之” (divide-and-conquer) 策略。</p>
<p>决策树的生成是一个递归过程.在决策树基本算法中，有三种情形会导致递归返回:<br>(1) 当前结点包含的样本全属于同一类别，无需划分(已经可以得出是正样本还是负样本);<br>(2) 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分;<br>(3) 当前结点包含的样本集合为空，不能划分.</p>
<p>在第(2)种情形下，我们把当前结点标记为叶结点，井将其类别设定为该结点所含样本最多的类别;<br>在第(3) 种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别.<br>注意这两种情形的处理实质不同:情形(2)是在利用当前结点的后验分布，而情形(3)则是把父结点的样本分布作为当前结点的先验分布.</p>
<h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><p>决策树学习的关键是如何选择最优划分属性。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>“信息熵” (information entropy)是度量样本集合纯度最常用的一种指标.假定当前样本集合D 中第k类样本所占的比例为Pk (k = 1, 2,. . . , IYI) ，则D的信息熵定义为:(值越小，则D的纯度越高)(在好瓜坏瓜分类中，可以理解为好瓜比例远高于坏瓜比例，或者反过来，因为通过求导可以知道，就是要使得样本比例中某一部分远高于其他；依此，用信息熵最小，就可以知道挑出某样本的“可行率”,若信息熵值越高，则越混乱(平均)，纯度越低)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息熵.png" style="zoom:100%;">



<p>假定离散属性a有V个可能的取值，给分支结点赋予权重IDVI / IDI ，即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集D进行划分所获得的”信息增益” (information gain)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息增益.png" style="zoom:75%;">

<p>一般而言，信息增益越大(子类的信息熵更小，因此说明这个分类器更能挑)，则意味着使周属性a来进行划分所获得的”纯度提升”越大.因此，我们可用信息增益来进行决策树的划分属性选择。ID3 决策树学习算法(Iterative Dichotomiser 迭代二分器)就是以信息增益为准则来选择划分属性。</p>
<p>通过在每个叶子节点计算使用剩余的所有可用属性会在此处的信息增益，挑出最高的作为此叶子节点的判别属性，就可以获得决策树(ID3决策树)</p>
<h3 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h3><p>但是信息增益准则也有坏处，信息增益准则对可取值数目较多的属性有所偏好。比如，将所有的样本单独分为一分支，这样每个节点仅有一个样本，分支节点纯度已达最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测.</p>
<p>为减少这种偏好可能带来的不利影响，著名的 C4.5 决策树算法不直接使用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性.采用与式(4.2) 相同的符号表示，增益率定义为：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/增益率.png" style="zoom:100%;">

<p>其中:属性a的”固有值”:属性a的可能取值数目越多(即V越大)，则IV(a) 的值通常会越大.</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/固有值.png" style="zoom:100%;">

<p>由于增益率准则对可取值数目较少的属性有所偏好，因此 C4.5决策树算法不直接使用增益率，而是 : 先从候选划分属性中找出信息增益高于平均水平的属性，再从<br>中选择增益率最高的.</p>
<h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><p>CART 决策树使用”基尼指数” (Gini index)来选择划分属性.数据集D的纯度可用基尼值来度量:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼值.png" style="zoom:100%;">

<p>直观来说， Gini(D) 反映了从数据集D中随机抽取两个样本其类别标记不一致的概率.因此，Gini(D) 越小，则数据集D 的纯度越高.</p>
<p>属性α 的基尼指数定义为：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼指数.png" style="zoom:100%;">

<p>于是，CART 决策树在候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性</p>
<a id="more"></a>

<h2 id="剪枝处理"><a href="#剪枝处理" class="headerlink" title="剪枝处理"></a>剪枝处理</h2><p>剪枝(pruning)是决策树学习算法对付”过拟合”的主要手段.在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得”太好”了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合.因此，可通过主动去掉一些分支来降低过拟合的风险.</p>
<p>决策树剪枝的基本策略有”预剪枝” (prepruning)和”后剪枝”(post”pruning) [Quinlan, 1993].<br>预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点;<br>后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点.</p>
<p>注：常见的性能评估的方法<br>1、留出法<br>2、交叉验证法<br>3、自助法</p>
<h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>预页剪枝使得决策树的很多分支都没有”展开“，这降低了过拟合的风险，也显著减少了决策树训练的时间开销和测试时间开销，.但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高;预剪枝基于”贪心”本质禁止这些分支展开给预剪枝决策树带来了欠拟含的风险。</p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>后剪枝决策树通常比预剪枝决策树保留了更多的分支. 一般情形下?后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的,并且要白底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多.</p>
<h2 id="连续与缺失"><a href="#连续与缺失" class="headerlink" title="连续与缺失"></a>连续与缺失</h2><h3 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h3><p>下面讨论如何在决策树学习中使用连续属性.</p>
<p>最简单的策略是采用二分法(bi-partition)对连续属性进行处理，这是C4.5决策树算法中采用的机制.</p>
<p>也可以尝试多个位置进行二划分，对每种划分计算其二分后的信息增益，选择能使得信息增益最大的二分点：(这正是基于信息增益划分而改来的)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/连续值处理的信息增益.png" style="zoom:80%;">

<p>其中Gain(D, a, t) 是样本集D基于划分点t二分后的信息增益. 于是，我们就可选择使Gain(D, a, t) 最大化的划分点.</p>
<p>需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性.</p>
<p>例如在父结点上使用了”密度&lt;0.381” ，不会禁止在子结点上使用”密度&gt;0.294” .</p>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>现实任务中常会遇到不完整样本，即样本的某些属性值缺失.如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，是对数据信息极大的浪费.</p>
<p>我们需解决两个问题:<br>(1) 如何在属性值缺失的情况下进行划分属性选择?(训练)<br>(2) 给定划分属性,若样本在该属性上的值缺失，如何对样本进行划分?(使用)</p>
<p>定义：对属性a，ρ表示无缺失值样本所占的比例，Pk表示无缺失值样本中第k 类所占的比例，Rv 则表示无缺失值样本中在属性a上取值v的样本所占的比例。基于上述定义，我们可将信息增益的计算式推广为:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/缺失值信息增益.png" style="zoom:80%;">

<p>Ent信息熵与之前的上面式子相同:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息熵.png" style="zoom:100%;">

<p>对问题(2) ，若样本x在划分属性a上的取值己知,则将x划入与其取值对应的子结点，且样本权值在于结点中保持为ωx.<br>若样本x在划分属性α 上的取值未知，则将x同时划入所有子结点，且样本权值在与属性值av对应的子结点中调整为Rv*ωx ，直观地看，这就是让同一个样本以不同的概率划入到不同的子结点中去.</p>
<p>这就是C4.5决策树算法使用的解决方案。</p>
<h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><p>若我们把每个属性视为坐标空间中的一个坐标轴，则d个属性描述的样本就对应了d维空间中的一个数据点，对样本分类则意味着在这个坐标空间中寻找不同类样本之间的分类边界.</p>
<p>分类边界的每一段都是与坐标轴平行的这样的分类边界使得学习结果有较好的可解释性，因为每一段划分都直接对应了某个属性取值.但在学习任务的真实分类边界比较复杂时，必须使用很多段划分才能获得较好的近似;此时的决策树会相当复杂，由于要进行大量的属性测试，预测时间开销会很大：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/决策树分类边界.png" style="zoom:100%;">

<p>若能使用斜的划分边界，如下图中红色线段所示，则决策树模型将大为简化”多变量决策树” (multivariate decision tree) 就是能实现这样的”斜划分”甚至更复杂划分的决策树.以实现斜划分的多变量决策树为例，在此类决策树中，非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树分类边界.png" style="zoom:100%;">

<p>于是，与传统的”单变量决策树” (univariate decision tree) 不同，在多变量决策树的学习过程中，<br>不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。</p>
<p>例如生成这样的决策树：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树1.png" style="zoom:100%;">

<p>其对应分类边界就会如下图所示：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树2.png" style="zoom:100%;">

<p>关于线性分类器，前面有谈到，其最基础的思想即是使得均方误差最小化。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>决策树学习算法最著名的代表是ID3 [1979, 1986] 、C4.5 [1993] 和CART [1984]. </p>
<p>在信息增益、增益率、基尼指数之外，人们还设计了许多其他的准则用于决策树划分选择，然而有实验研究[1989]表明，这些准则虽然对决策树的尺寸有较大影响，但对泛化性能的影响很有限.</p>
<p>剪枝方法和程度对决策树泛化性能的影响相当显著，有实验研究表明[1989]，在数据带有噪声时通过剪枝甚至可将决策树的泛化性能提高25%.</p>
<p>多变量决策树算法主要有OC1 [1994] 和[Brodley and Utgoff,1995] 提出的一系列算法.OC1 先贪心地寻找每个属性的最优权值，在局部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界; [Brodley and Utgoff, 1995] 则直接引入了线性分类器学习的最小二乘法，还有一些算法试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如”感知机树” (Perceptron tree) [Utgoff, 1989b] 在决策树的每个叶结点上训练一个感知机，而[Guo and Gelfand, 1992] 则直接在叶结点上嵌入多层神经网络.</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>相机运动方向检测2</title>
    <url>/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/</url>
    <content><![CDATA[<h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p>关于之前开的相机运动方向检测的代码实现，目前已经大致完成</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result_mainPage.png" style="zoom:100%;">

<p>总共有五个测试视频，效果如下：</p>
<a id="more"></a>

<p>测试视频1：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result1.gif" style="zoom:100%;">

<p>测试视频2：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result2.gif" style="zoom:100%;">

<p>测试视频3：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result3.gif" style="zoom:100%;">

<p>测试视频4：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result4.gif" style="zoom:100%;">

<p>测试视频5：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result5.gif" style="zoom:100%;">

<h3 id="测试数据来源"><a href="#测试数据来源" class="headerlink" title="测试数据来源"></a>测试数据来源</h3><p>关于测试的视频来源，为 Hopkins 155 数据库。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>线性模型2</title>
    <url>/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/</url>
    <content><![CDATA[<h2 id="类别"><a href="#类别" class="headerlink" title="类别"></a>类别</h2><h3 id="线性模型中的多分类学习"><a href="#线性模型中的多分类学习" class="headerlink" title="线性模型中的多分类学习"></a>线性模型中的多分类学习</h3><p>现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。</p>
<p> 多分类学习的基本思路是”拆解法”，即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成.最经典的拆分策略有三种. “一对一” (One vs. One，简称OvO) 、”一对其余” (One vs. Rest ，简称OvR)和”多对多” (Many vs. Many，简称MvM)。</p>
<h4 id="OvO与OvR"><a href="#OvO与OvR" class="headerlink" title="OvO与OvR"></a>OvO与OvR</h4><p>OvO 将N 个类别两两配对，从而产生N(N 一1)/2 个二分类任务，最终结果可通过投票产生。OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器.在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果。若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。下图为OvO与OvR的示意图：</p>
<img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/OvO与OvR.png" style="zoom:80%;">



<p>OvR只需训练N个分类器， 而OvO需训练N(N - 1)/2 个分类器， 因此， OvO的存储开销和测试间开销通常比OvR 更大. 但在训练时，OvR的每个分类器均使用全部训练样例，而OvO的每个分类器仅用到两个类的样例，因此，在类别很多时，OvO的训练时间开销通常比OvR更小. 预测性能在多数情形下两者差不多.</p>
<h4 id="MvM"><a href="#MvM" class="headerlink" title="MvM"></a>MvM</h4><p>MvM 是每次将若干个类作为正类，若干个其他类作为反类. MvM的正、反类构造必须有特殊的设计，不能随意选取.最常用的MvM技术是”纠错输出码” (Error CorrectingOutput Codes，简称ECOC).它尽可能在解码过程中具有容错性. </p>
<h5 id="Error-CorrectingOutput-Codes-ECOC"><a href="#Error-CorrectingOutput-Codes-ECOC" class="headerlink" title="Error CorrectingOutput Codes(ECOC)"></a>Error CorrectingOutput Codes(ECOC)</h5><p>ECOC 工作过程主要分为两步:<br>编码:对N个类别做M次划分， 每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集;这样一共产生M个训练集，可训练出M个分类器.<br>解码:M个分类器分别对测试样本进行预测，这些预测标记组成一个编码.将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果.</p>
<img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/ECOC.png" style="zoom:80%;">

<p>ECOC 编码示意图”+1” 、”-1” 分别表示学习器f将该类样本作为正、反例;三元码中”0” 表示f不使用该类样本<br>一般来说，对同一个学习任务， ECOC 编码越长，纠错能力越强.然而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大;另外，对有限类别数，可能的组合数目是有限的。</p>
<p>对OvR 、MvM 来说，由于对每个类进行了相同的处理，其拆解出的二分类任务中类别不平衡的影响会相互抵消，因此通常不需专门处理.</p>
<h3 id="类别不平衡问题-class-imbalance"><a href="#类别不平衡问题-class-imbalance" class="headerlink" title="类别不平衡问题(class-imbalance)"></a>类别不平衡问题(class-imbalance)</h3><p>如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰.例如有998个反例，但正例只有2个，那么学习方法只需返回一个永远将新样本预测为反例的学习器，就能达到99.8%的精度;然而这样的学习器往往没有价值，因为它不能预测出任何正例.</p>
<a id="more"></a>

<h4 id="再缩放"><a href="#再缩放" class="headerlink" title="再缩放"></a>再缩放</h4><p>再缩放，又称为再平衡，是不平衡学习的一个基本策略。</p>
<p>通常在二分类情况下，我们实际上是在使用预测出的y值与阈值比较从而获得分类的结果：当y&gt;0.5，我们称之为正例，y&lt;=0.5，我们称之为反例。即：y/(1-y)&gt;1为正例。<br>再缩放的基本思想，即正例： y/(1-y)&gt;(m+)/(m-) ；m+为正样本数量 ，m-为负样本数量。因此运用到实际预测当中时，有：f= y/(1-y) * (m+)/(m-) </p>
<p>但是，我们未必能有效地基于训练集观测几率来准确地推断出真实几率.因此现有技术大体上有三类做法:第一类是直接对训练集里的反类样例进行”欠采样” (undersampling) ，即去除一些反倒使得正、反例数日接近然后再进行学习;<br>第二类是对训练集里的正类样例进行”过来样” (oversampling) ，即增加一些正例使得正、反例数目接近，然后再进行学习;<br>第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式(3.48)嵌入到其决策过程中，称为”阔值移动” (threshold-moving).</p>
<p>欠采样法的时间开销通常远小于过采样法，因为前者丢弃了很多反例，使得分类器训练集远小子初始训练集，而过来样法增加了很多正例，其训练集大于初始训练集.<br>需注意的是，过采样法不能简单地对初始正例样本进行重复来样，否则会招致严重的过拟合，过采样法的代表性算法SMOTE是通过对训练集里的正例进行插值来产生额外的正例.<br>另一方面，欠采样法若随机丢弃反例可能丢失一些重要信息;欠采样法的代表性算法EasyEnsemble则是利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息.</p>
<p>最后值得一提的是，”再缩放”也是”代价敏感学习” (cost-sensitive learning) 的基础。代价敏感学习为不同类的错误设定了不同的权值，其错误率计算为：<br><img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/代价敏感学习错误率.png" style="zoom:80%;"><br>cost即为被预测为不同类预测错误时所需付出的代价。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>线性模型1</title>
    <url>/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/</url>
    <content><![CDATA[<h2 id="线性模型的基本形式"><a href="#线性模型的基本形式" class="headerlink" title="线性模型的基本形式"></a>线性模型的基本形式</h2><img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/基本形式.png" style="zoom:100%;">

<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>“线性回归” (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。通常使用均方误差，亦称平方损失，来作为性能度量，试图使均方误差最小。</p>
<p>基于均方误差最小化来进行模型求解的方法称为”最小二乘法” (least suare method). 在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.(最小二乘法用途很广，不仅限于线性回归)</p>
<p>在求解使得均方差最小化的过程中，称为线性回归模型对最小二乘的参数估计。我们可对其均方差求导，另求导式为零，则可得w与b的最优解。</p>
<p>然而现实中，往往会求出多个解。这时选择哪一个作为解进行输出，则由算法的归纳偏好决定。常见的做法是引入正则化(regularization) 项.如，假设我们认为示例所对应的输出标记是在指数尺度上变化，则可以使得 lny = wx +b 。这就是”对数线性回归” (log-linear regression)。</p>
<p>更一般地，考虑单调可微函数g(.) ， 令 g(y) = wx + b , 这样得到的模型称为” 广义线性模型” (generalized linear model) ，其中函数g() 称为”联系函数” (link function)。</p>
<h3 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h3><p>若要做的是分类任务，只需找一个单调可做函数将分类任务的真实标记y与线性回归模型的预测值联系起来。</p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/单位阶跃函数与对数几率函数.png" style="zoom:100%;">

<p>上图中，左式是对数几率函数；右式是单位阶跃函数</p>
<p>从图3.2 可看出，单位阶跃函数不连续，因此不能直接使用，于是我们使用另外的单调可微的连续函数：对数几率函数。</p>
<p>对数几率函数是一种”Sigmoid 函数” (Sigmoid 函数即形似s的函数)，它将z值转化为一个接近0或1 的y值并且其输出值在z=0 附近变化很陡.将对数几率函数作为g()使用于广义线性模型 g(y) = wx + b 中即可将分类标记与回归模型联系起来。</p>
<p>这个方法是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为”对数几率回归”，虽然它的名字是”回归”，但实际是一种分类学习方法。</p>
<p>在其求解中，我们可通过”极大似然法” (maximum likelihood method)来估计ω和b。即令每个样本属于其真实标记的概率越大越好。最终得出的式子是关于β 的高阶可导连续凸函数，根据凸优化理论，经典的数值优化算法如梯度下降法(gradient descent method) 、牛顿法(Newton method)等都可求得其最优解。</p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>有一可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快。因为梯度的方向就是函数之变化最快的方向。所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是测量下降方向的手段。</p>
<p>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率；在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向。</p>
<a id="more"></a>

<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/梯度下降例子.png" style="zoom:90%;">

<p>如上，梯度就是分别对每个变量进行微分，梯度是一个向量。 </p>
<h5 id="模拟梯度下降的python代码"><a href="#模拟梯度下降的python代码" class="headerlink" title="模拟梯度下降的python代码"></a>模拟梯度下降的python代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#python3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集大小 即20个数据点</span></span><br><span class="line">m = <span class="number">20</span></span><br><span class="line"><span class="comment"># x的坐标以及对应的矩阵</span></span><br><span class="line">X0 = ones((m, <span class="number">1</span>))  <span class="comment"># 生成一个m行1列的向量，也就是x0，全是1</span></span><br><span class="line">X1 = arange(<span class="number">1</span>, m+<span class="number">1</span>).reshape(m, <span class="number">1</span>)  <span class="comment"># 生成一个m行1列的向量，也就是x1，从1到m</span></span><br><span class="line">X = hstack((X0, X1))  <span class="comment"># 按照列堆叠形成数组，其实就是样本数据</span></span><br><span class="line"><span class="comment"># 对应的y坐标</span></span><br><span class="line">Y = array([</span><br><span class="line">    <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">11</span>, <span class="number">8</span>, <span class="number">12</span>,</span><br><span class="line">    <span class="number">11</span>, <span class="number">13</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">21</span></span><br><span class="line">]).reshape(m, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(theta, X, Y)</span>:</span></span><br><span class="line">    diff = dot(X, theta) - Y  <span class="comment"># dot() 数组需要像矩阵那样相乘，就需要用到dot()</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>/(<span class="number">2</span>*m)) * dot(diff.transpose(), diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数对应的梯度函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_function</span><span class="params">(theta, X, Y)</span>:</span></span><br><span class="line">    diff = dot(X, theta) - Y</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>/m) * dot(X.transpose(), diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span><span class="params">(X, Y, alpha)</span>:</span></span><br><span class="line">    theta = array([<span class="number">1</span>, <span class="number">1</span>]).reshape(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    gradient = gradient_function(theta, X, Y)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> all(abs(gradient) &lt;= <span class="number">1e-5</span>):</span><br><span class="line">        theta = theta - alpha * gradient</span><br><span class="line">        gradient = gradient_function(theta, X, Y)</span><br><span class="line">    <span class="comment">#当梯度小于1e-5时，说明已经进入了比较平滑的状态，类似于山谷的状态,</span></span><br><span class="line">    <span class="comment">#这时候再继续迭代效果也不大了，所以这个时候可以退出循环</span></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line">optimal = gradient_descent(X, Y, alpha)</span><br><span class="line">print(<span class="string">'optimal:'</span>, optimal)</span><br><span class="line">print(<span class="string">'cost function:'</span>, cost_function(optimal, X, Y)[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据数据画出对应的图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(X, Y, theta)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)  <span class="comment">#</span></span><br><span class="line">    ax.scatter(X, Y, s=<span class="number">30</span>, c=<span class="string">"red"</span>, marker=<span class="string">"s"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"X"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Y"</span>)</span><br><span class="line">    x = arange(<span class="number">0</span>, <span class="number">21</span>, <span class="number">0.2</span>)  <span class="comment"># x的范围</span></span><br><span class="line">    y = theta[<span class="number">0</span>] + theta[<span class="number">1</span>]*x</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot(X1, Y, optimal)</span><br></pre></td></tr></table></figure>



<h3 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h3><p>线性判别分析(Linear Discriminant Analysis，简称LDA)，其思想：给定训练样例集设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。</p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/线性判别分析二维示意图.png" style="zoom:100%;">

<p>LDA 的二维示意图：”+”、” “分别代表正例和反例，椭圆表示数据簇的外轮廓，虚线表示投影， 红色实心园和实心三角形分别表示两类样本投影后的中心点.</p>
<p>欲使同类样例的投影点尽可能接近，可以让同类样例投影点的协方差尽可能小;而欲使异类样例的投影点尽可能远离，可以让类中心之间的距离尽可能大。</p>
<p>另J=类中心之间的距离/同类样例投影点的协方差，另J最大化。利用拉格朗日乘子法、奇异值分解等操作，最终即可求解。</p>
<p>推广至N维空间的情况，若将样本投影到N-1维空间，则可以进行降维，且投影过程中使用了类别信息，因此LDA也常被视为一种经典的监督降维技术。</p>
<h4 id="拉格朗日乘数法"><a href="#拉格朗日乘数法" class="headerlink" title="拉格朗日乘数法"></a>拉格朗日乘数法</h4><img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/拉格朗日乘数法1.png" style="zoom:70%;">

<p>假设有自变量x和y，给定约束条件g(x,y)=c，要求f(x,y)在约束g下的极值。可以画出f的等高线图，如上图。此时，约束g=c由于只有一个自由度，因此也是图中的一条曲线（红色曲线所示）。当约束曲线g=c与某一条等高线f=d1相切时，函数f取得极值。两曲线相切等价于两曲线在切点处拥有共线的法向量。因此可得函数f(x,y)与g(x,y)在切点处的梯度（gradient）成正比。</p>
<p>因为两条曲线相切，意味着他们在这点的法线平行，也就是法向量只差一个任意的常数乘子。 </p>
<p>于是我们便可以列出方程组求解切点的坐标(x,y)，进而得到函数f的极值。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>相机运动方向检测1</title>
    <url>/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/</url>
    <content><![CDATA[<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>代码实现相机运动方向的检测，用于后面的相机运动补偿。<br>目前还未完成，本篇仅为今日的小结</p>
<h2 id="算法大致思路"><a href="#算法大致思路" class="headerlink" title="算法大致思路"></a>算法大致思路</h2><p>该算法思路仅为当前思路，后续还会继续改进</p>
<p>对于每一帧：<br>1、提取其Surf特征点<br>2、与上一帧的特征点进行匹配，这里可以使用FlannBased与BruteForceMatcher，FlannBased更快而BruteForceMatcher更精确；考虑到视频处理的实时性，本人目前使用FlannBased<br>3、基于距离筛除一些不太可能的匹配，此步骤的前提是场景不会发生形变<br>4、根据已经匹配的特征点及其移动距离与方向，从而获取当前相机在此参考系下的移动情况</p>
<h3 id="主要使用到数据结构与对象"><a href="#主要使用到数据结构与对象" class="headerlink" title="主要使用到数据结构与对象"></a>主要使用到数据结构与对象</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv::Ptr&lt;SurfFeatureDetector&gt; detector;<span class="comment">//检测器</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::KeyPoint&gt; key_points_1, key_points_2;<span class="comment">//提取的特征点序列</span></span><br><span class="line">cv::Mat descriptors1, descriptors2;<span class="comment">//特征描述子</span></span><br><span class="line">cv::Ptr&lt;cv::DescriptorMatcher&gt; matcher = </span><br><span class="line">    cv::DescriptorMatcher::create(<span class="string">"FlannBased"</span>);<span class="comment">//FlannBased匹配</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::DMatch&gt; dmatches;<span class="comment">//匹配序列</span></span><br></pre></td></tr></table></figure>

<h3 id="目前进度"><a href="#目前进度" class="headerlink" title="目前进度"></a>目前进度</h3><img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/match1.png" style="zoom:125%;">

<a id="more"></a>

<p>2020-02-08:</p>
<img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/result.gif" style="zoom:125%;">

<p>2020-02-10:</p>
<p>优化了筛除误匹配算法的部分，更加减少了误匹配的情况：</p>
<img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/result2.gif" style="zoom:125%;">

]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪3</title>
    <url>/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/</url>
    <content><![CDATA[<p>继上篇，以下为2月7日研究《Moving Objects Detection with a Moving Camera: A Comprehensive Review》的运动分割法部分的笔记</p>
<h3 id="Motion-segmentation-运动分割法2"><a href="#Motion-segmentation-运动分割法2" class="headerlink" title="Motion segmentation 运动分割法2"></a>Motion segmentation 运动分割法2</h3><p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(2015)提出了一个基于轨迹的分水岭分割算法。在应用一个双边的滤波器去柔化图像并增强edges后，无关梯度会被最小化，并且将轨迹点选为标签。这些标签将会用于watershed algorithm (分水岭算法,根据分水岭的构成来考虑图像的分割) 的seeds从而获得分割结果。在这个结果中，会根据轨迹的标签，将分割结果的相应标为前景与背景。最后，利用马尔可夫随机场算法(Markov Random Field，MRF)，让其中的能量函数最小化，使得用前景背景信息推断没有标签的部分的标签。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P1_2015.png" style="zoom:75%;">

<p>上图中，红色点代表为检测出的背景部分，蓝色点代表检测出的前景部分；其中有一些由于噪点而误检测的特征点可以使用PCA算法筛除</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了Multi-Layer Background Subtraction(多层的背景差法)。他们使用了多标签的分割，而非二值标签的分割。每一个动作集群点都会被联系到一层中。在每一层中，像素的动作都会由Gaussian Belief Propagation (GaBP)(高斯置信度传播算法)评估。之后，由外观模型、先前的概率图、motion estimation(动作评估)去计算之后的概率图。多标签的分割是正是基于由MRF算法中最小化能量函数得出的概率图计算的。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P2_2017.png" style="zoom:75%;">

<a id="more"></a>


<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)基于光度和光流方向场，使用Canny detector来计算动作的边界 。他们还利用了对下一帧的前景位置预测，从而防止了不可靠的光度与方向的前景流场(foreground flow field)。</p>
<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)使用了三种不同的聚类方法来分割三维的动作情况，从而获得前景背景的二值掩码。这三种方法是：simple k-means clustering（k-means聚类算法),spectral clustering(谱聚类算法) with a 4-connected graph,spectral clustering with fully connected graph。<br>k-means clustering:基于欧式距离来划分不同的类<br>spectral clustering: 将带权无向图划分为两个或两个以上的最优子图，使子图内部尽量相似，而子图间距离尽量距离较远 </p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)提出了一种双判断的机制来区分前景物体与背景。前景是由前景与背景之间的阈值差别+FlowNet2.0一起共同判断出来的。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪2</title>
    <url>/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/</url>
    <content><![CDATA[<p>以下为阅读《Moving Objects Detection with a Moving Camera: A Comprehensive Review》随读笔记</p>
<h3 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h3><p>运动分割法的大体思路为利用特征点的轨迹来分割每一帧，分成静态背景与移动物体。</p>
<img src="/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/运动分割法example.png" style="zoom:125%;">

<p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(oct 2015)提出：根据特征点的轨迹相似度，并利用PCA算法(主成分分析算法)筛除false trajectories，从而获取几类集群特征点。</p>
<p>《a probabilistic model for causal motion segmentation in moving camera videos》(2016)使用了稠密光流差、旋转流差，从而获得了物体的移动流。然后由平移流(translational flow)估计角度场，并根据每个平移流的平移大小作为该平移角度的可靠性指标，然后由符合条件的流动角度的可能性评估每个像素的流动方向。最后，用贝叶斯公式(Bayes’ rule)获得每个像素的次可能移动，然后会被用于最后的分割当中。作者还提出了，利用一个修正的RANSAC算法选择3个超像素，然后用于去分割视频的第一帧，从而用于后续的估计背景的移动以抵消相机的晃动。</p>
<a id="more"></a>

<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)通过使用动作消失点从2D视角动作中获取3D动作，并得出背景的深度。</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了第一集群轨迹，它动态地基于集群对各个轨迹的标签的异同。通过计算集群内的变化点，各个集群可以分别对应各个前景物体。</p>
<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)的作者提出基于光度和光流方向场，利用Canny detector来计算动作的边界，从而获取初始 seeds 。其中，前景seeds是动作边缘上的点，而背景seeds是前景的动作检测方框上的点。</p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)基于FlowNet2.0得到稠密光流图。背景的光流是由Constrained RANSAC Algorithm(CRA)的二次变换函数计算出的。CRA是一种改进版本的RANSAC算法，它避免了过拟合并且改进了搜索效率。</p>
<p>《Flownet2.0: Evolution of optical flow estimation with deep networks》(2017)：FlowNet2.0是一种基于深度学习的光流预估算法。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪1</title>
    <url>/2020/02/03/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA1/</url>
    <content><![CDATA[<h1 id="Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera"><a href="#Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera" class="headerlink" title="Moving Objects Detection and Tracking with a Moving Camera"></a>Moving Objects Detection and Tracking with a Moving Camera</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在本块内容中，将针对移动相机的移动目标检测跟踪进行研究与实现。</p>
<h2 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h2><p>由学者Marie-Neige Chapela, Thierry Bouwmansb发表，在 15 Jan 2020 被收录的论文《Moving Objects Detection with a Moving Camera: A Comprehensive Review》中，将运动相机的运动目标检测方法大致分为两类：一类称为one Plane类，将背景视为flat scenes来处理；第二类将背景作为several parts来处理。</p>
<h3 id="one-Plane作为单平面处理类"><a href="#one-Plane作为单平面处理类" class="headerlink" title="one Plane作为单平面处理类"></a>one Plane作为单平面处理类</h3><h4 id="Panoramic-background-subtraction-全背景减法"><a href="#Panoramic-background-subtraction-全背景减法" class="headerlink" title="Panoramic background subtraction 全背景减法"></a>Panoramic background subtraction 全背景减法</h4><p>一个移动的照相机捕捉到的图像可以被缝在一起形成一个较大的图像，即所谓的全景图或镶嵌图，从而可以再次作为一个静态相机处理。</p>
<h4 id="多相机法"><a href="#多相机法" class="headerlink" title="多相机法"></a>多相机法</h4><p>一些方法使用双摄像头系统，而不是构建全景图，两个摄像机使得具有广泛的视角来观察整体现场。</p>
<h4 id="Motion-compensation-运动补偿法"><a href="#Motion-compensation-运动补偿法" class="headerlink" title="Motion compensation 运动补偿法"></a>Motion compensation 运动补偿法</h4><p>补偿相机的运动，使得能使用应对静态相机的方法</p>
<h4 id="Subspace-segmentation-子空间分割法"><a href="#Subspace-segmentation-子空间分割法" class="headerlink" title="Subspace segmentation 子空间分割法"></a>Subspace segmentation 子空间分割法</h4><p>利用特征点的轨迹用来分离背景和前景。</p>
<h4 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h4><p>与子空间分割法类似，利用特征点的轨迹，将视频的每一帧分割成静态的背景或移动的物体，但不使用子空间</p>
<h3 id="several-parts方法类"><a href="#several-parts方法类" class="headerlink" title="several parts方法类"></a>several parts方法类</h3><h4 id="平面处理-视差处理"><a href="#平面处理-视差处理" class="headerlink" title="平面处理+视差处理"></a>平面处理+视差处理</h4><p>平面+视差分解法，是以场景为中心的方法；对主要的平面进行运动补偿</p>
<h4 id="Multi-planes-scene-representation-多平面的场景表示"><a href="#Multi-planes-scene-representation-多平面的场景表示" class="headerlink" title="Multi planes scene representation 多平面的场景表示"></a>Multi planes scene representation 多平面的场景表示</h4><p>利用RANSAC级联器算法区分各个平面后处理</p>
<h4 id="网格分割图像法"><a href="#网格分割图像法" class="headerlink" title="网格分割图像法"></a>网格分割图像法</h4><p>利用网格分割图像后进行处理</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>My First Blog in here</title>
    <url>/2020/01/01/FirstBlog/</url>
    <content><![CDATA[<p>欢迎来到吴泽鑫的博客！</p>
<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h2><h3 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h3><h4 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h4><p> <a href="https://github.com/TheXeme" target="_blank" rel="noopener">https://github.com/TheXeme</a></p>
<h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><h4 id="GithubBlog"><a href="#GithubBlog" class="headerlink" title="GithubBlog"></a>GithubBlog</h4><p> <a href="https://thexeme.github.io/">https://thexeme.github.io/</a></p>
<h4 id="GiteeBlog"><a href="#GiteeBlog" class="headerlink" title="GiteeBlog"></a>GiteeBlog</h4><p><a href="https://thexeme.gitee.io/" target="_blank" rel="noopener">https://thexeme.gitee.io/</a></p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
