<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>相机运动方向检测1</title>
    <url>/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/</url>
    <content><![CDATA[<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>代码实现相机运动方向的检测，用于后面的相机运动补偿。<br>目前还未完成，本篇仅为今日的小结</p>
<h2 id="算法大致思路"><a href="#算法大致思路" class="headerlink" title="算法大致思路"></a>算法大致思路</h2><p>该算法思路仅为当前思路，后续还会继续改进</p>
<p>对于每一帧：<br>1、提取其Surf特征点<br>2、与上一帧的特征点进行匹配，这里可以使用FlannBased与BruteForceMatcher，FlannBased更快而BruteForceMatcher更精确；考虑到视频处理的实时性，本人目前使用FlannBased<br>3、基于距离筛除一些不太可能的匹配，此步骤的前提是场景不会发生形变<br>4、根据已经匹配的角点及其移动距离与方向，从而获取当前相机在此参考系下的移动情况</p>
<h3 id="主要使用到数据结构与对象"><a href="#主要使用到数据结构与对象" class="headerlink" title="主要使用到数据结构与对象"></a>主要使用到数据结构与对象</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cv::Ptr&lt;SurfFeatureDetector&gt; detector;<span class="comment">//检测器</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::KeyPoint&gt; key_points_1, key_points_2;<span class="comment">//提取的特征点序列</span></span><br><span class="line">cv::Mat descriptors1, descriptors2;<span class="comment">//特征描述子</span></span><br><span class="line">cv::Ptr&lt;cv::DescriptorMatcher&gt; matcher = </span><br><span class="line">    cv::DescriptorMatcher::create(<span class="string">"FlannBased"</span>);<span class="comment">//FlannBased匹配</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cv::DMatch&gt; dmatches;<span class="comment">//匹配序列</span></span><br></pre></td></tr></table></figure>

<h3 id="目前进度"><a href="#目前进度" class="headerlink" title="目前进度"></a>目前进度</h3><img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/match1.png" style="zoom:125%;">

<img src="/2020/02/08/%E7%9B%B8%E6%9C%BA%E8%BF%90%E5%8A%A8%E6%96%B9%E5%90%91%E6%A3%80%E6%B5%8B1/result.gif" style="zoom:125%;">]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪3</title>
    <url>/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/</url>
    <content><![CDATA[<p>继上篇，以下为2月7日研究《Moving Objects Detection with a Moving Camera: A Comprehensive Review》的运动分割法部分的笔记</p>
<h3 id="Motion-segmentation-运动分割法2"><a href="#Motion-segmentation-运动分割法2" class="headerlink" title="Motion segmentation 运动分割法2"></a>Motion segmentation 运动分割法2</h3><p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(2015)提出了一个基于轨迹的分水岭分割算法。在应用一个双边的滤波器去柔化图像并增强edges后，无关梯度会被最小化，并且将轨迹点选为标签。这些标签将会用于watershed algorithm (分水岭算法,根据分水岭的构成来考虑图像的分割) 的seeds从而获得分割结果。在这个结果中，会根据轨迹的标签，将分割结果的相应标为前景与背景。最后，利用马尔可夫随机场算法(Markov Random Field，MRF)，让其中的能量函数最小化，使得用前景背景信息推断没有标签的部分的标签。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P1_2015.png" style="zoom:75%;">

<p>上图中，红色点代表为检测出的背景部分，蓝色点代表检测出的前景部分；其中有一些由于噪点而误检测的特征点可以使用PCA算法筛除</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了Multi-Layer Background Subtraction(多层的背景差法)。他们使用了多标签的分割，而非二值标签的分割。每一个动作集群点都会被联系到一层中。在每一层中，像素的动作都会由Gaussian Belief Propagation (GaBP)(高斯置信度传播算法)评估。之后，由外观模型、先前的概率图、motion estimation(动作评估)去计算之后的概率图。多标签的分割是正是基于由MRF算法中最小化能量函数得出的概率图计算的。</p>
<img src="/2020/02/07/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA3/P2_2017.png" style="zoom:75%;">

<a id="more"></a>


<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)基于光度和光流方向场，使用Canny detector来计算动作的边界 。他们还利用了对下一帧的前景位置预测，从而防止了不可靠的光度与方向的前景流场(foreground flow field)。</p>
<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)使用了三种不同的聚类方法来分割三维的动作情况，从而获得前景背景的二值掩码。这三种方法是：simple k-means clustering（k-means聚类算法),spectral clustering(谱聚类算法) with a 4-connected graph,spectral clustering with fully connected graph。<br>k-means clustering:基于欧式距离来划分不同的类<br>spectral clustering: 将带权无向图划分为两个或两个以上的最优子图，使子图内部尽量相似，而子图间距离尽量距离较远 </p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)提出了一种双判断的机制来区分前景物体与背景。前景是由前景与背景之间的阈值差别+FlowNet2.0一起共同判断出来的。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪2</title>
    <url>/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/</url>
    <content><![CDATA[<p>以下为阅读《Moving Objects Detection with a Moving Camera: A Comprehensive Review》随读笔记</p>
<h3 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h3><p>运动分割法的大体思路为利用特征点的轨迹来分割每一帧，分成静态背景与移动物体。</p>
<img src="/2020/02/05/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA2/运动分割法example.png" style="zoom:125%;">

<p>《Background subtraction for moving cameras based on trajectory-controlled segmentation and label inference》(oct 2015)提出：根据特征点的轨迹相似度，并利用PCA算法(主成分分析算法)筛除false trajectories，从而获取几类集群特征点。</p>
<p>《a probabilistic model for causal motion segmentation in moving camera videos》(2016)使用了稠密光流差、旋转流差，从而获得了物体的移动流。然后由平移流(translational flow)估计角度场，并根据每个平移流的平移大小作为该平移角度的可靠性指标，然后由符合条件的流动角度的可能性评估每个像素的流动方向。最后，用贝叶斯公式(Bayes’ rule)获得每个像素的次可能移动，然后会被用于最后的分割当中。作者还提出了，利用一个修正的RANSAC算法选择3个超像素，然后用于去分割视频的第一帧，从而用于后续的估计背景的移动以抵消相机的晃动。</p>
<a id="more"></a>

<p>《Moving object segmentation using depth and optical flow in car driving sequences》(2016)通过使用动作消失点从2D视角动作中获取3D动作，并得出背景的深度。</p>
<p>《A multilayer-based framework for online back-ground subtraction with freely moving cameras》(2017)提出了第一集群轨迹，它动态地基于集群对各个轨迹的标签的异同。通过计算集群内的变化点，各个集群可以分别对应各个前景物体。</p>
<p>《Online background subtraction with freely moving cameras using different motion boundaries》(2018)的作者提出基于光度和光流方向场，利用Canny detector来计算动作的边界，从而获取初始 seeds 。其中，前景seeds是动作边缘上的点，而背景seeds是前景的动作检测方框上的点。</p>
<p>《An efficient optical flow based motion detection method for non-stationary scenes》(2019)基于FlowNet2.0得到稠密光流图。背景的光流是由Constrained RANSAC Algorithm(CRA)的二次变换函数计算出的。CRA是一种改进版本的RANSAC算法，它避免了过拟合并且改进了搜索效率。</p>
<p>《Flownet2.0: Evolution of optical flow estimation with deep networks》(2017)：FlowNet2.0是一种基于深度学习的光流预估算法。</p>
<h2 id="论文来源"><a href="#论文来源" class="headerlink" title="论文来源"></a>论文来源</h2><p>论文来源：《Moving Objects Detection with a Moving Camera: A Comprehensive Review》<br>Marie-Neige Chapela, Thierry Bouwmansb<br>aLab. L3I, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>bLab. MIA, LRUniv., Avenue Albert Einstein, 17000 La Rochelle, France<br>[cs.CV] 15 Jan 2020</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>运动相机下的运动目标跟踪1</title>
    <url>/2020/02/03/%E8%BF%90%E5%8A%A8%E7%9B%B8%E6%9C%BA%E4%B8%8B%E7%9A%84%E8%BF%90%E5%8A%A8%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA1/</url>
    <content><![CDATA[<h1 id="Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera"><a href="#Moving-Objects-Detection-and-Tracking-with-a-Moving-Camera" class="headerlink" title="Moving Objects Detection and Tracking with a Moving Camera"></a>Moving Objects Detection and Tracking with a Moving Camera</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在本块内容中，将针对移动相机的移动目标检测跟踪进行研究与实现。</p>
<h2 id="方法概述"><a href="#方法概述" class="headerlink" title="方法概述"></a>方法概述</h2><p>由学者Marie-Neige Chapela, Thierry Bouwmansb发表，在 15 Jan 2020 被收录的论文《Moving Objects Detection with a Moving Camera: A Comprehensive Review》中，将运动相机的运动目标检测方法大致分为两类：一类称为one Plane类，将背景视为flat scenes来处理；第二类将背景作为several parts来处理。</p>
<h3 id="one-Plane作为单平面处理类"><a href="#one-Plane作为单平面处理类" class="headerlink" title="one Plane作为单平面处理类"></a>one Plane作为单平面处理类</h3><h4 id="Panoramic-background-subtraction-全背景减法"><a href="#Panoramic-background-subtraction-全背景减法" class="headerlink" title="Panoramic background subtraction 全背景减法"></a>Panoramic background subtraction 全背景减法</h4><p>一个移动的照相机捕捉到的图像可以被缝在一起形成一个较大的图像，即所谓的全景图或镶嵌图，从而可以再次作为一个静态相机处理。</p>
<h4 id="多相机法"><a href="#多相机法" class="headerlink" title="多相机法"></a>多相机法</h4><p>一些方法使用双摄像头系统，而不是构建全景图，两个摄像机使得具有广泛的视角来观察整体现场。</p>
<h4 id="Motion-compensation-运动补偿法"><a href="#Motion-compensation-运动补偿法" class="headerlink" title="Motion compensation 运动补偿法"></a>Motion compensation 运动补偿法</h4><p>补偿相机的运动，使得能使用应对静态相机的方法</p>
<h4 id="Subspace-segmentation-子空间分割法"><a href="#Subspace-segmentation-子空间分割法" class="headerlink" title="Subspace segmentation 子空间分割法"></a>Subspace segmentation 子空间分割法</h4><p>利用特征点的轨迹用来分离背景和前景。</p>
<h4 id="Motion-segmentation-运动分割法"><a href="#Motion-segmentation-运动分割法" class="headerlink" title="Motion segmentation 运动分割法"></a>Motion segmentation 运动分割法</h4><p>与子空间分割法类似，利用特征点的轨迹，将视频的每一帧分割成静态的背景或移动的物体，但不使用子空间</p>
<h3 id="several-parts方法类"><a href="#several-parts方法类" class="headerlink" title="several parts方法类"></a>several parts方法类</h3><h4 id="平面处理-视差处理"><a href="#平面处理-视差处理" class="headerlink" title="平面处理+视差处理"></a>平面处理+视差处理</h4><p>平面+视差分解法，是以场景为中心的方法；对主要的平面进行运动补偿</p>
<h4 id="Multi-planes-scene-representation-多平面的场景表示"><a href="#Multi-planes-scene-representation-多平面的场景表示" class="headerlink" title="Multi planes scene representation 多平面的场景表示"></a>Multi planes scene representation 多平面的场景表示</h4><p>利用RANSAC级联器算法区分各个平面后处理</p>
<h4 id="网格分割图像法"><a href="#网格分割图像法" class="headerlink" title="网格分割图像法"></a>网格分割图像法</h4><p>利用网格分割图像后进行处理</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>My First Blog in here</title>
    <url>/2020/01/01/FirstBlog/</url>
    <content><![CDATA[<p>欢迎来到吴泽鑫的博客！</p>
<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h2><h3 id="代码仓库"><a href="#代码仓库" class="headerlink" title="代码仓库"></a>代码仓库</h3><h4 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h4><p> <a href="https://github.com/TheXeme" target="_blank" rel="noopener">https://github.com/TheXeme</a></p>
<h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><h4 id="GithubBlog"><a href="#GithubBlog" class="headerlink" title="GithubBlog"></a>GithubBlog</h4><p> <a href="https://thexeme.github.io/">https://thexeme.github.io/</a></p>
<h4 id="GiteeBlog"><a href="#GiteeBlog" class="headerlink" title="GiteeBlog"></a>GiteeBlog</h4><p><a href="https://thexeme.gitee.io/" target="_blank" rel="noopener">https://thexeme.gitee.io/</a></p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
